{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Library Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu'est ce que c'est ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face est une entreprise qui a un rôle très important dans la communauté open source en intelligence artificiel. C'est d'une part un site qui regroupe des datasets, des modèles et des \"spaces\" et d'autre part plusieurs librarys (transformers, diffusers et datasets principalement).  \n",
    "<img src=\"images/HG_logo.png\" alt=\"nlp\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pourquoi utiliser Hugging Face ?** Hugging Face permet d'avoir accès à des modèles complexes de l'état de l'art de manière simple et de pouvoir utiliser des modèles complexes rapidement et efficacement. Il est aussi possible de tester des modèles via la catégorie \"spaces\" de leur site et de télécharger des datasets de la communauté. C'est un peu le \"github\" du deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu'est ce qu'on va apprendre dans ce cours ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce cours est moins théorique que les précédents mais va permettre de toucher à des modèles très performants et de voir les capacités des modèles de deep learning actuels. Ce cours s'inspire des ressources disponbles sur le [site de Hugging Face](https://huggingface.co/) et du cours gratuit sur [deeplearning.ai](https://www.deeplearning.ai/) intitulé \"Open Source Models with Hugging Face\". Je vous invite à consulter ce cours qui montre de nombreuses applications en vision, audio et NLP.  \n",
    "\n",
    "Le plan de ce cours est le suivant :  \n",
    "- Dans l'introduction (ici), nous présentons le [site de Hugging Face](https://huggingface.co/) avec les 3 principales catégories : Models, Datasets et Spaces. \n",
    "- Les 3 notebooks suivants sont dédiés à l'utilisation de la library transformers : le premier traîte des modèles de vision, le second du NLP et le troisième de l'audio. \n",
    "- Après cela, un notebook sera dedié à la library diffusers qui permet d'utiliser des modèles de diffusion (Stable diffusion par exemple) pour génerer des images.  \n",
    "- Le dernier notebook présente gradio, une library permettant de faire des interfaces rapidement pour des démos par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Site de Hugging Face](https://huggingface.co/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La catégorie la plus ludique et la plus facile d'accès est la catégorie **spaces** qui regroupe des démos de différents modèles.   \n",
    "\n",
    "La page d'accueil se présente comme cela :   \n",
    "\n",
    "<img src=\"images/Spaces.png\" alt=\"nlp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les démos (spaces) sont classé par utilisation et par \"trending\" mais vous pouvez utiliser la fonction \"Search spaces\" pour chercher un modèle particulier que vous souhaiteriez tester.  \n",
    "Je vous conseille également de parcourir régulierement les différents spaces, cela permet de se tenir au courant des nouveautés dans le domaine du deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous entraînez vous-même un modèle, vous pouvez ensuite le partager gratuitement dans un space via l'outil de création \"Create New Space\". Pour cela, il faut avoir les bases de la library gradio qui nous traiterons dans le dernier notebook de ce cours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfois, un modèle que vous voudriez tester n'est pas disponible dans les spaces ou alors il est disponible mais vous voulez l'utiliser dans votre propre code. Pour cela, il faudra passer par la catégorie **Models** du site. \n",
    "La page **Models** regroupe énormement de modèles open-source.   \n",
    "\n",
    "Voici à quoi ressemble la page :   \n",
    "\n",
    "<img src=\"images/Models.png\" alt=\"nlp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y beaucoup d'information sur cette page. D'une part, vous pouvez chercher un modèle particulier dont vous connaissez le nom via \"Filter by name\".   \n",
    "Vous pouvez également utiliser les filtres à gauche pour une recherche de modèles par catégorie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, imaginons que je cherche un modèle de \"zero-shot object detection\", ce qui permet de détecter n'importe quel objet sur l'image à partir d'un prompt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt, qu'est ce que c'est ?** : Un prompt est une entrée qui permet de guide la modèle dans sa tâche. En NLP, un prompt va simplement être l'entrée du modèle, c'est-à-dire le texte saisi par l'utilisateur. Un prompt peut également être une coordonée sur une image (pour une tâche de segmentation) ou même une image ou encore une vidéo. La plupart du temps, lorsqu'on fait référence à prompt, c'est pour parler d'un ajout de texte en input du modèle.   \n",
    "Dans le cas du \"zero-shot object detection\", si je cherche à détecter les bananes sur un image, l'entrée de mon modèle sera l'image et le texte \"banana\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chercher un modèle qui pourrait me convenir, j'utilise le filtrage de gauche en séléctionnant la catégorie zero-shot object detection et je consulte les modèles proposés.   \n",
    "\n",
    "<img src=\"images/zeroshot.png\" alt=\"nlp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle \"IDEA-Research/grounding-dino-tiny\" me parait bien, je le selectionne et j'arrive sur la page suivante :\n",
    "  \n",
    "<img src=\"images/modelcard.png\" alt=\"nlp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **model card** donne une description précise du modèle (son fonctionnement, ses capacités etc ...).   \n",
    "Pour obtenir le code permettant de l'utiliser directement en python (via la library transformers ou diffusers en fonction du modèle choisi), vous pouvez utiliser le bouton **Use this model**.  \n",
    "\n",
    "Pour le modèle choisi, on aura le bout de code suivant :  \n",
    "\n",
    "<img src=\"images/code.png\" alt=\"nlp\" width=\"500\"/>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les notebooks suivants, nous verrons comment utiliser ce code pour notre tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous souhaitez entraîner votre propre modèle, il est nécessaire d'avoir un dataset. Vous pouvez choisir de le créer vous-même mais il existe beaucoup de datasets open-source que l'on peut notamment trouver sur Hugging Face. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La page **Datasets** se présente comme la page **Models** avec les fonctions de filtrage et la fonction de recherche : \n",
    "\n",
    "<img src=\"images/datasets.png\" alt=\"nlp\" width=\"800\"/>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez sélectionner un dataset et tomber sur la page suivante : \n",
    " \n",
    "<img src=\"images/datasetpage.png\" alt=\"nlp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les modèles, la **Dataset card** permet de visualiser les données du dataset et d'avoir une description de celui-ci. Pour l'utiliser directement en python, vous pouvez utiliser **Use in Datasets library** pour obtenir le code python correspondant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autres catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le site est plus complet que ça mais cette introduction ne vise pas à être exhaustive. Je vous invite à naviguer par vous-même sur le site pour trouver des choses qui vous interessent.   \n",
    "Dans les notebooks suivants, nous présenterons une vue d'ensemble des types de modèles disponibles et leur utilisation en python via Hugging Face. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
