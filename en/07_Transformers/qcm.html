<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Quiz</title>
    
    <!-- Ajout de MathJax pour les équations LaTeX -->
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['\\(', '\\)'], ['$', '$']],
                displayMath: [['\\[', '\\]'], ['$$', '$$']]
            }
        };
    </script>
    
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            min-height: 100vh;
            padding: 2rem 1rem;
            line-height: 1.6;
        }

        .header {
            text-align: center;
            margin-bottom: 3rem;
            color: white;
        }

        .header h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            text-shadow: 0 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.1rem;
            opacity: 0.9;
            font-weight: 300;
        }

        .qcm-container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
            position: relative;
        }

        .qcm-container::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 6px;
            background: linear-gradient(90deg, #667eea, #764ba2);
        }

        .question-container {
            padding: 2rem;
            border-bottom: 1px solid #f0f0f0;
            transition: all 0.3s ease;
        }

        .question-container:last-child {
            border-bottom: none;
        }

        .question-header {
            display: flex;
            align-items: center;
            margin-bottom: 1.5rem;
        }

        .question-number {
            background: linear-gradient(135deg, #636e72, #2d3436);
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            margin-right: 1rem;
            flex-shrink: 0;
        }

        .question-text {
            font-size: 1.1rem;
            color: #2d3748;
            font-weight: 500;
            flex: 1;
        }

        .answers {
            display: grid;
            gap: 0.8rem;
        }

        .answer-button {
            display: flex;
            align-items: center;
            width: 100%;
            padding: 1rem 1.2rem;
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 12px;
            font-size: 1rem;
            color: #495057;
            cursor: pointer;
            transition: all 0.3s ease;
            text-align: left;
            position: relative;
            overflow: hidden;
        }

        .answer-button::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.4), transparent);
            transition: left 0.5s;
        }

        .answer-button:hover::before {
            left: 100%;
        }

        .answer-button:hover {
            background: #e3f2fd;
            border-color: #2196f3;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(33, 150, 243, 0.2);
        }

        .answer-option {
            background: #636e72;
            color: white;
            width: 28px;
            height: 28px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            margin-right: 0.8rem;
            flex-shrink: 0;
            font-size: 0.9rem;
        }

        .answer-text {
            flex: 1;
        }

        .answer-button.correct {
            background: linear-gradient(135deg, #48bb78, #38a169);
            border-color: #38a169;
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(72, 187, 120, 0.3);
        }

        .answer-button.correct .answer-option {
            background: rgba(255,255,255,0.2);
        }

        .answer-button.incorrect {
            background: linear-gradient(135deg, #f56565, #e53e3e);
            border-color: #e53e3e;
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(245, 101, 101, 0.3);
        }

        .answer-button.incorrect .answer-option {
            background: rgba(255,255,255,0.2);
        }

        .answer-button.show-correct {
            background: linear-gradient(135deg, #4299e1, #3182ce);
            border-color: #3182ce;
            color: white;
            animation: highlight 1s ease;
        }

        .answer-button.show-correct .answer-option {
            background: rgba(255,255,255,0.2);
        }

        @keyframes highlight {
            0%, 100% { transform: translateY(-2px); }
            50% { transform: translateY(-4px); }
        }

        .answer-button:disabled {
            cursor: not-allowed;
        }

        .feedback {
            margin-top: 1rem;
            padding: 1rem;
            border-radius: 12px;
            font-weight: 500;
            display: flex;
            align-items: center;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .feedback.correct {
            background: linear-gradient(135deg, #c6f6d5, #9ae6b4);
            color: #22543d;
        }

        .feedback.incorrect {
            background: linear-gradient(135deg, #fed7d7, #feb2b2);
            color: #742a2a;
        }

        .feedback-icon {
            margin-right: 0.5rem;
            font-size: 1.2rem;
        }

        .progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 4px;
            background: linear-gradient(90deg, #667eea, #764ba2);
            transition: width 0.3s ease;
            z-index: 1000;
        }

        .score-container {
            background: linear-gradient(135deg, #f7fafc, #edf2f7);
            padding: 2rem;
            text-align: center;
            border-top: 1px solid #e2e8f0;
        }

        .score-text {
            font-size: 1.2rem;
            color: #2d3748;
            font-weight: 600;
        }

        /* Styles pour le formatage Markdown améliorés */
        em {
            font-style: italic;
            color: inherit;
            font-weight: 500;
        }

        strong {
            font-weight: 700;
            color: #2d3748;
        }

        code {
            background: linear-gradient(135deg, #f1f5f9, #e2e8f0);
            padding: 0.2rem 0.4rem;
            border-radius: 6px;
            font-family: 'JetBrains Mono', 'Fira Code', monospace;
            font-size: 0.9em;
            color: #667eea;
            border: 1px solid #e2e8f0;
        }

        /* Navigation */
        .navigation-bar {
            position: fixed;
            top: 20px;
            left: 20px;
            right: 20px;
            z-index: 1001;
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
        }

        .nav-btn {
            background: rgba(255, 255, 255, 0.95);
            color: #2c3e50;
            border: 2px solid rgba(44, 62, 80, 0.2);
            padding: 12px 20px;
            border-radius: 25px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
            font-size: 14px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            display: flex;
            align-items: center;
            gap: 8px;
            text-decoration: none;
        }

        .nav-btn:hover {
            background: rgba(44, 62, 80, 0.9);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.2);
        }

        .nav-btn i {
            font-size: 12px;
        }

        .next-page-btn {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border: 2px solid rgba(255, 255, 255, 0.2);
        }

        .next-page-btn:hover {
            background: linear-gradient(135deg, #5a6fd8, #6a4190);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }

        /* Responsive design */
        @media (max-width: 768px) {
            .qcm-container {
                margin: 0;
                border-radius: 0;
            }
            
            .question-container {
                padding: 1.5rem;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .navigation-bar {
                top: 10px;
                left: 10px;
                right: 10px;
                flex-direction: column;
                gap: 10px;
            }
            
            .nav-btn {
                padding: 10px 16px;
                font-size: 13px;
                width: 100%;
                justify-content: center;
            }
        }
    </style>
</head>
<body>
<div class="navigation-bar">
    <button class="nav-btn" onclick="goBackToCourse()">
        <i class="fas fa-arrow-left"></i> Back to course
    </button>
    <button class="nav-btn next-page-btn" onclick="goToNextPage()">
        Next page <i class="fas fa-arrow-right"></i>
    </button>
</div>
<div class="progress-bar" id="progressBar"></div>

<div class="header">
    <h1><i class="fas fa-brain"></i> Interactive Quiz</h1>
    <p>Test your knowledge!</p>
</div>

<div class="qcm-container">

    
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">1</div>
                <div class="question-text">What is the main difference between an autoregressive model (like GPT) and an encoder model (like BERT) in natural language processing?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 1)" data-question="1">
                    <div class="answer-option">A</div>
                    <div class="answer-text">The autoregressive model predicts masked words in a sentence, while the encoder model predicts the next word.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 1)" data-question="1">
                    <div class="answer-option">B</div>
                    <div class="answer-text">The autoregressive model generates a token based solely on previous tokens, whereas the encoder model considers both left and right context of a token.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 1)" data-question="1">
                    <div class="answer-option">C</div>
                    <div class="answer-text">The encoder model works only for translation, while the autoregressive model works for all NLP tasks.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 1)" data-question="1">
                    <div class="answer-option">D</div>
                    <div class="answer-text">The autoregressive model uses a full architecture with cross-attention, unlike the encoder model.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">2</div>
                <div class="question-text">What is the role of the Query (Q), Key (K), and Value (V) matrices in the self-attention mechanism of a transformer?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, true, 'A', 2)" data-question="2">
                    <div class="answer-option">A</div>
                    <div class="answer-text">Q represents what each position is looking for, K what it contains, and V the actual value to extract if deemed relevant.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'A', 2)" data-question="2">
                    <div class="answer-option">B</div>
                    <div class="answer-text">Q is a masked version of the input, K is a normalized version, and V is the final output.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'A', 2)" data-question="2">
                    <div class="answer-option">C</div>
                    <div class="answer-text">Q, K, and V are identical matrices used to compute a weighted average.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'A', 2)" data-question="2">
                    <div class="answer-option">D</div>
                    <div class="answer-text">Q contains the weights, K contains the biases, and V contains the network activations.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">3</div>
                <div class="question-text">In the transformer architecture, what is the purpose of residual connections between attention and feed-forward layers?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 3)" data-question="3">
                    <div class="answer-option">A</div>
                    <div class="answer-text">They allow increasing the model size without changing its depth.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 3)" data-question="3">
                    <div class="answer-option">B</div>
                    <div class="answer-text">They facilitate the training of deep models by preventing the vanishing gradient problem.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 3)" data-question="3">
                    <div class="answer-option">C</div>
                    <div class="answer-text">They normalize activations between layers.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 3)" data-question="3">
                    <div class="answer-option">D</div>
                    <div class="answer-text">They mask future tokens in the decoder.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">4</div>
                <div class="question-text">In the implementation of a bigram language model, what is the main limitation that explains the poor quality of generated texts?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, true, 'A', 4)" data-question="4">
                    <div class="answer-option">A</div>
                    <div class="answer-text">It predicts the next character based solely on a single context character.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'A', 4)" data-question="4">
                    <div class="answer-option">B</div>
                    <div class="answer-text">It uses an encoder architecture instead of a decoder.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'A', 4)" data-question="4">
                    <div class="answer-option">C</div>
                    <div class="answer-text">It applies incorrect masking of future tokens.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'A', 4)" data-question="4">
                    <div class="answer-option">D</div>
                    <div class="answer-text">It lacks the normalization layer (layer norm).</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">5</div>
                <div class="question-text">What is the main difference between the self-attention layer used in a decoder and the one in a transformer encoder?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 5)" data-question="5">
                    <div class="answer-option">A</div>
                    <div class="answer-text">The encoder layer applies a lower triangular mask, the decoder layer does not.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 5)" data-question="5">
                    <div class="answer-option">B</div>
                    <div class="answer-text">The decoder layer masks future tokens via a lower triangular matrix, whereas the encoder layer does not mask.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 5)" data-question="5">
                    <div class="answer-option">C</div>
                    <div class="answer-text">The encoder layer uses cross-attention, the decoder layer does not.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 5)" data-question="5">
                    <div class="answer-option">D</div>
                    <div class="answer-text">The decoder layer uses multiple attention heads, the encoder layer uses only one.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">6</div>
                <div class="question-text">In the Vision Transformer (ViT), how are images processed before being passed into the transformer?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 6)" data-question="6">
                    <div class="answer-option">A</div>
                    <div class="answer-text">Images are transformed into sequences of individual pixels.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 6)" data-question="6">
                    <div class="answer-option">B</div>
                    <div class="answer-text">Images are divided into fixed patches (e.g., 16x16), flattened, and then projected into an embedding space.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 6)" data-question="6">
                    <div class="answer-option">C</div>
                    <div class="answer-text">Images are transformed into feature maps by a CNN before the transformer.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 6)" data-question="6">
                    <div class="answer-option">D</div>
                    <div class="answer-text">Images are converted to grayscale before being processed.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">7</div>
                <div class="question-text">What is the purpose of the 'class token' in the Vision Transformer?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 7)" data-question="7">
                    <div class="answer-option">A</div>
                    <div class="answer-text">To enable text generation from an image.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 7)" data-question="7">
                    <div class="answer-option">B</div>
                    <div class="answer-text">To provide a special token dedicated to classification, avoiding the need to aggregate all transformer outputs.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 7)" data-question="7">
                    <div class="answer-option">C</div>
                    <div class="answer-text">To replace position embedding in the transformer.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 7)" data-question="7">
                    <div class="answer-option">D</div>
                    <div class="answer-text">To enable masking of patches in the image.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">8</div>
                <div class="question-text">What is the main innovation of the Swin Transformer compared to the Vision Transformer?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 8)" data-question="8">
                    <div class="answer-option">A</div>
                    <div class="answer-text">Use of an encoder and a decoder in the same architecture.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 8)" data-question="8">
                    <div class="answer-option">B</div>
                    <div class="answer-text">Application of attention only on hierarchical local windows with shifted windowing.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 8)" data-question="8">
                    <div class="answer-option">C</div>
                    <div class="answer-text">Switching from multi-head attention to a single attention head.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 8)" data-question="8">
                    <div class="answer-option">D</div>
                    <div class="answer-text">Exclusive use of convolutions instead of feed-forward layers.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">9</div>
                <div class="question-text">What is the advantage of relative position embedding in the Swin Transformer?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 9)" data-question="9">
                    <div class="answer-option">A</div>
                    <div class="answer-text">It replaces the attention mechanism.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 9)" data-question="9">
                    <div class="answer-option">B</div>
                    <div class="answer-text">It better captures spatial relationships between patches and adapts the model to different image resolutions.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 9)" data-question="9">
                    <div class="answer-option">C</div>
                    <div class="answer-text">It masks irrelevant patches in a window.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 9)" data-question="9">
                    <div class="answer-option">D</div>
                    <div class="answer-text">It increases the model's capacity to handle large images.</div>
                </button>
            
            </div>
        </div>
        
        <div class="question-container">
            <div class="question-header">
                <div class="question-number">10</div>
                <div class="question-text">What is the training principle of the CLIP model that associates text and image?</div>
            </div>
            <div class="answers">
        
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 10)" data-question="10">
                    <div class="answer-option">A</div>
                    <div class="answer-text">Supervised training with precise annotation of objects in images.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, true, 'B', 10)" data-question="10">
                    <div class="answer-option">B</div>
                    <div class="answer-text">Contrastive training with positive pairs (image-description) and negative pairs to maximize correct correlation.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 10)" data-question="10">
                    <div class="answer-option">C</div>
                    <div class="answer-text">Generation of images from textual descriptions.</div>
                </button>
            
                <button class="answer-button" onclick="checkAnswer(this, false, 'B', 10)" data-question="10">
                    <div class="answer-option">D</div>
                    <div class="answer-text">Prediction of the next text token from an image.</div>
                </button>
            
            </div>
        </div>
        
    <div class="score-container">
        <div class="score-text" id="scoreDisplay">Score: 0/10</div>
    </div>

    <div class="score-container">
        <div class="score-text" id="scoreDisplay">Score: 0/10</div>
    </div>
</div>

<script>
    let totalQuestions = 10;
    let answeredQuestions = 0;
    let correctAnswers = 0;

    function updateProgress() {
        const progress = (answeredQuestions / totalQuestions) * 100;
        document.getElementById('progressBar').style.width = progress + '%';
    }

    function updateScore() {
        document.getElementById('scoreDisplay').innerHTML = `Score: ${correctAnswers}/${totalQuestions}`;
    }

    function goBackToCourse() {
        if (document.referrer && document.referrer.includes(window.location.hostname)) {
            window.history.back();
        } else {
            window.location.href = './';
        }
    }

    function goToNextPage() {
        window.location.href = "../08_DetectionEtYolo/01_Introduction.html";
    }

    function checkAnswer(button, isCorrect, correctAnswer, questionNumber) {
        const questionContainer = button.closest('.question-container');
        const buttons = questionContainer.querySelectorAll('.answer-button');
        
        buttons.forEach(btn => {
            btn.disabled = true;
        });

        if (!button.hasAttribute('data-answered')) {
            answeredQuestions++;
            button.setAttribute('data-answered', 'true');
        }

        let feedbackHtml = '';
        
        if (isCorrect) {
            button.classList.add('correct');
            correctAnswers++;
            feedbackHtml = `
                <div class="feedback correct">
                    <i class="fas fa-check-circle feedback-icon"></i>
                    Excellent! You found the correct answer.
                </div>
            `;
        } else {
            button.classList.add('incorrect');
            
            buttons.forEach(btn => {
                const optionText = btn.querySelector('.answer-text').textContent;
                const optionLetter = btn.querySelector('.answer-option').textContent;
                if ((optionLetter + ') ' + optionText).startsWith(correctAnswer)) {
                    btn.classList.add('show-correct');
                }
            });
            
            feedbackHtml = `
                <div class="feedback incorrect">
                    <i class="fas fa-times-circle feedback-icon"></i>
                    Incorrect! The correct answer was: <strong>${correctAnswer}</strong>
                </div>
            `;
        }

        if (!questionContainer.querySelector('.feedback')) {
            questionContainer.insertAdjacentHTML('beforeend', feedbackHtml);
        }

        updateProgress();
        updateScore();
        
        if (window.MathJax) {
            MathJax.typesetPromise([questionContainer]).then(() => {
                console.log('MathJax re-rendered');
            }).catch((err) => console.log(err.message));
        }
    }

    document.addEventListener('DOMContentLoaded', function() {
        const questions = document.querySelectorAll('.question-container');
        questions.forEach((question, index) => {
            question.style.opacity = '0';
            question.style.transform = 'translateY(20px)';
            setTimeout(() => {
                question.style.transition = 'all 0.5s ease';
                question.style.opacity = '1';
                question.style.transform = 'translateY(0)';
            }, index * 100);
        });
    });
</script>
    
</body>
</html>