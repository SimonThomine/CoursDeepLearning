{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we will explore techniques to improve the reliability and ease of training neural networks.\n",
    "To illustrate these techniques, we use the [MNIST](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST) dataset, which contains images of handwritten digits from 1 to 9.\n",
    "The goal is to make the network take an image as input and identify the digit it represents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we download the MNIST dataset. The torchvision library allows managing images with PyTorch and provides tools to load common datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=T.ToTensor() # Pour convertir les éléments en tensor torch directement\n",
    "dataset = datasets.MNIST(root='./../data', train=True, download=True,transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./../data', train=False,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le chiffre sur l'image est un 5\n"
     ]
    }
   ],
   "source": [
    "# On peut visualiser les éléments du dataset\n",
    "plt.imshow(dataset[0][0].permute(1,2,0).numpy(), cmap='gray')\n",
    "plt.show()\n",
    "print(\"Le chiffre sur l'image est un \"+str(dataset[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation/Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, when loading the dataset, we have a *train_dataset* and a *test_dataset*. This is an essential practice for training a neural network.\n",
    "Indeed, a network trained on data performs well on the same data. Therefore, we need to create a *test dataset* to evaluate the model on data not seen during training.\n",
    "\n",
    "In practice, we use 3 subsets:\n",
    "- The *training split* for model training.\n",
    "- The *validation split* to evaluate the model during training.\n",
    "- The *test split* to evaluate the model at the end of training (this is the most important result).\n",
    "\n",
    "A common practice is to use a 60-20-20 split, meaning 60% of the data for training, 20% for validation, and 20% for testing. However, this recommendation does not apply to all datasets. If the dataset contains many images, we can reduce the share of validation and test data. For example, for datasets with billions of images, we often use splits like 98-1-1 or even 99.8-0.1-0.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le train et test sont déjà séparé, on va donc séparer le train_dataset en train et validation\n",
    "train_dataset, validation_dataset=torch.utils.data.random_split(dataset, [0.8,0.2])\n",
    "\n",
    "# Création des dataloaders pour séparer en mini-batch automatiquement\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader= DataLoader(validation_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training an Initial Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous notebook, we create a fully connected model for training. Since the input data are images of size $28 \\times 28$, we need to convert them into a 1D vector of size $28 \\times 28=784$ to pass them into the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) # première couche cachée \n",
    "    self.fc2=nn.Linear(256,256) # seconde couche cachée \n",
    "    self.fc3=nn.Linear(256,10) # couche de sortie\n",
    "    \n",
    "  # La fonction forward est la fonction appelée lorsqu'on fait model(x)\n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28) # Pour convertir l'image de taille 28x28 en tensor de taille 784\n",
    "    x=F.relu(self.fc1(x)) # le F.relu permet d'appliquer la fonction d'activation ReLU sur la sortie de notre couche \n",
    "    x=F.relu(self.fc2(x))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Nombre de paramètres 269322\n"
     ]
    }
   ],
   "source": [
    "model = mlp()\n",
    "print(model)\n",
    "print(\"Nombre de paramètres\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loss function, we use the *cross entropy loss* from PyTorch, which corresponds to the loss function of logistic regression for more than 2 classes.\n",
    "The loss function is written as follows:\n",
    "$\\text{Cross Entropy Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{ic} \\log(p_{ic})$\n",
    "where:\n",
    "- $N$ is the number of examples in the *mini-batch*.\n",
    "- $C$ is the number of classes.\n",
    "- $y_{ic}$ is the target value ($1$ if the example belongs to class $c$ and $0$ otherwise).\n",
    "- $p_{ic}$ is the predicted probability of belonging to class $c$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En pytorch\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training (may take a few minutes depending on your computer's power).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.29076647758483887\n",
      "step 0 val loss 0.15385286509990692\n",
      "step 1 train loss 0.10695428401231766\n",
      "step 1 val loss 0.10097559541463852\n",
      "step 2 train loss 0.07086848467588425\n",
      "step 2 val loss 0.09286081790924072\n",
      "step 3 train loss 0.05028771981596947\n",
      "step 3 val loss 0.08867377787828445\n",
      "step 4 train loss 0.04254501312971115\n",
      "step 4 val loss 0.0835222601890564\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model on Test Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can check its performance on the *testing split*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.69\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieves very good accuracy in the testing phase, which is a good sign.\n",
    "However, we notice that during training, the *training loss* is lower than the *validation loss*. This is an important point to consider, as it indicates that the model is slightly *overfitting*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting and Underfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key element of deep learning is the model's ability to avoid *overfitting* the training data. *Overfitting* refers to a model that has learned too well on the training data but is unable to generalize to new elements from the same distribution.\n",
    "To understand the concept, here is a figure that shows the difference between *underfitting* (a model too simple to learn the complexity of the data), a well-trained model, and *overfitting*.\n",
    "\n",
    "![Overfitting](./images/overfitting.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the most critical case of *overfitting*, the model has almost perfect accuracy on the training data but performs poorly on the validation and test data.\n",
    "In this course, we will introduce 2 methods to avoid this *overfitting* problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 regularization is a method that involves adding a penalty to the loss based on the value of the model's weights. This penalty is proportional to the square of the weight values (note that there is also L1 regularization, which is linearly proportional to the weight values). This penalty encourages the model's weights to remain small and less sensitive to the noise in the training data.\n",
    "L2 regularization can be formulated as follows:\n",
    "$L(w) = L_0(w) + \\lambda \\sum_{i=1}^{n} w_i^2$\n",
    "where:\n",
    "- $L(w)$ is the regularized loss.\n",
    "- $L_0(w)$ is the classic loss function.\n",
    "- $\\lambda$ is the regularization coefficient.\n",
    "- $w_i$ is a weight of the model.\n",
    "\n",
    "To learn more about L2 regularization, you can consult the [bonus course on regularization](../Bonus_CoursSpécifiques/06_Regularisation.ipynb) or this [blogpost](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the model by adding regularization. In PyTorch, regularization is applied by adding the *weight_decay* parameter to our *optimizer*. The value of *weight_decay* corresponds to the $\\lambda$ in the previous equation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.2986273467540741\n",
      "step 0 val loss 0.1439662128686905\n",
      "step 1 train loss 0.11165566742420197\n",
      "step 1 val loss 0.10781095176935196\n",
      "step 2 train loss 0.07492929697036743\n",
      "step 2 val loss 0.09555892646312714\n",
      "step 3 train loss 0.05378309637308121\n",
      "step 3 val loss 0.08672302216291428\n",
      "step 4 train loss 0.041800014674663544\n",
      "step 4 val loss 0.0883878618478775\n"
     ]
    }
   ],
   "source": [
    "model_with_reg=mlp()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_reg.parameters(),lr=learning_rate,weight_decay=1e-5)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_reg(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_reg(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.73\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_reg(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is not striking, but we notice a reduction in the difference between the validation loss and the training loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition**: L2 regularization works because by penalizing large coefficients, it promotes solutions where the weights are more evenly distributed. This reduces the model's sensitivity to specific variations in the training data and thus improves the model's robustness and generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another regularization method is *dropout*. This method involves randomly deactivating a percentage of neurons in the network at each training step (the deactivated weights change during training). Each neuron in a layer has a probability $p$ of being deactivated.\n",
    "\n",
    "This technique forces the network not to rely on certain neurons but rather to learn more robust representations that generalize better. We can see *dropout* as a kind of ensemble of models where each model is different (because some neurons are deactivated). During the testing phase, we take the \"average\" of these different models. During the testing phase, *dropout* is deactivated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply *dropout*, it must be added directly to the network architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_dropout(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) \n",
    "    self.dropout1 = nn.Dropout(0.2) # on désactive 20% des neurones aléatoirement\n",
    "    self.fc2=nn.Linear(256,256) \n",
    "    self.dropout2 = nn.Dropout(0.2) # on désactive 20% des neurones aléatoirement\n",
    "    self.fc3=nn.Linear(256,10) \n",
    "  \n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28)\n",
    "    x=F.relu(self.dropout1(self.fc1(x)))\n",
    "    x=F.relu(self.dropout2(self.fc2(x)))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.3267715573310852\n",
      "step 0 val loss 0.19353896379470825\n",
      "step 1 train loss 0.13504144549369812\n",
      "step 1 val loss 0.14174170792102814\n",
      "step 2 train loss 0.10012412816286087\n",
      "step 2 val loss 0.13484247028827667\n",
      "step 3 train loss 0.07837768644094467\n",
      "step 3 val loss 0.10895466059446335\n",
      "step 4 train loss 0.0631122887134552\n",
      "step 4 val loss 0.10599609464406967\n"
     ]
    }
   ],
   "source": [
    "model_with_dropout=mlp_dropout()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_dropout.parameters(),lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_dropout(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_dropout(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  96.96\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_dropout(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a slight improvement in the training results again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition**: *Dropout* improves generalization by randomly deactivating neurons during training. This prevents the model from relying too much on certain neurons and forces a more robust and diverse distribution of learned features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another technique to improve the training of a neural network is *Batch Normalization* (*BatchNorm*). The principle is to normalize the inputs of each layer of the network with a distribution having a mean of zero and a variance of 1.\n",
    "Normalization is performed on the entire *batch* as follows:\n",
    "\n",
    "For a *mini-batch* $B$ with activations $x$:\n",
    "- $\\mu_B = \\frac{1}{m} \\sum_{i=1}^m x_i$: the mean of the activations $x_i$ of the $m$ elements.\n",
    "- $\\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i - \\mu_B)^2$: the variance of the activations $x_i$ of the $m$ elements.\n",
    "- $\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$: the normalized value of $x_i$.\n",
    "- $y_i = \\gamma \\hat{x}_i + \\beta$: adding the parameters $\\gamma$ and $\\beta$ allows the network to learn the optimal activation distributions.\n",
    "\n",
    "where:\n",
    "- $m$ is the size of the *mini-batch* $B$.\n",
    "- $\\epsilon$ is a small constant added to avoid division by zero.\n",
    "- $\\gamma$ and $\\beta$ are learnable parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we observe 4 main advantages when using *BatchNorm*:\n",
    "- **Training Acceleration**: Normalizing the inputs of each layer allows using a higher *learning rate* and thus accelerating training convergence.\n",
    "- **Reduction in Sensitivity to Weight Initialization**: *BatchNorm* helps stabilize the distribution of activations, making the network less sensitive to weight initialization.\n",
    "- **Improved Generalization**: Like *dropout* and L2 regularization, *BatchNorm* acts as a form of regularization. This is due to the noise introduced by normalizing over the *batch*.\n",
    "- **Reduction of \"Internal Covariate Shift\"**: Stabilizing activations throughout the network reduces changes in the distributions of internal layers, facilitating learning.\n",
    "\n",
    "The key takeaway is that *BatchNorm* offers many advantages, so it is advisable to use it systematically.\n",
    "\n",
    "There are also other normalization techniques such as *LayerNorm*, *InstanceNorm*, *GroupNorm*, and others.\n",
    "To learn more about *batch normalization*, you can take the [bonus course on *batch norm*](../Bonus_CoursSpécifiques/02_BatchNorm.ipynb), read the [paper](https://arxiv.org/pdf/1502.03167), or the [blogpost](https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739).\n",
    "For additional information on the benefits of normalization for training neural networks, you can consult the [blogpost](https://medium.com/nerd-for-tech/overview-of-normalization-techniques-in-deep-learning-e12a79060daf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement *BatchNorm* in PyTorch, it must be added directly to the model construction. Note that we often apply *BatchNorm* before the activation function, but both approaches are possible (before or after).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_bn(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) \n",
    "    self.bn1=nn.BatchNorm1d(256) # Batch Normalization\n",
    "    self.fc2=nn.Linear(256,256) \n",
    "    self.bn2=nn.BatchNorm1d(256) # Batch Normalization\n",
    "    self.fc3=nn.Linear(256,10) \n",
    "  \n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28)\n",
    "    x=F.relu(self.bn1(self.fc1(x)))\n",
    "    x=F.relu(self.bn1(self.fc2(x)))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.20796926319599152\n",
      "step 0 val loss 0.1327729970216751\n",
      "step 1 train loss 0.09048832952976227\n",
      "step 1 val loss 0.10177803039550781\n",
      "step 2 train loss 0.0635765939950943\n",
      "step 2 val loss 0.09861738979816437\n",
      "step 3 train loss 0.045849185436964035\n",
      "step 3 val loss 0.09643400460481644\n",
      "step 4 train loss 0.0397462323307991\n",
      "step 4 val loss 0.08524414896965027\n"
     ]
    }
   ],
   "source": [
    "model_with_bn=mlp_bn()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_bn.parameters(),lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_bn(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_bn(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.19\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_bn(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, *BatchNorm* allows achieving a better score on our data under the same training conditions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
