{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques avancées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cours, nous allons introduire des techniques permettant de fiabiliser et de faciliter l'entraînement des réseaux de neurones.  \n",
    "Pour démontrer l'intêret de ces techniques, nous allons prendre le dataset [MNIST](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST) qui regroupe des images de chiffres tracés à la main allant de 1 à 9.  \n",
    "Le but de notre réseau va être de prendre une image en entrée et d'identifier le chiffre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, nous allons télécharger le dataset MNIST. La library torchvision permet la gestion des images sur pytorch et possède un outil pour charger les datasets communs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=T.ToTensor() # Pour convertir les éléments en tensor torch directement\n",
    "dataset = datasets.MNIST(root='./../data', train=True, download=True,transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./../data', train=False,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le chiffre sur l'image est un 5\n"
     ]
    }
   ],
   "source": [
    "# On peut visualiser les éléments du dataset\n",
    "plt.imshow(dataset[0][0].permute(1,2,0).numpy(), cmap='gray')\n",
    "plt.show()\n",
    "print(\"Le chiffre sur l'image est un \"+str(dataset[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation train/validation/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous l'aurez remarqué, lors du chargement du dataset, on a chargé un train_dataset et un test_dataset. C'est une pratique que nous n'avons pas encore abordée mais qui est d'une importance capitale lors d'un entraînement de réseau de neurones.  \n",
    "En effet, lorsque l'on entraîne un réseau sur des données, il est logique que celui-ci soit bon sur les données sur lesquelles il a été entraîné. Il est donc nécessaire de créer un dataset de test qui va servir à évaluer le modèle sur des données non vues pendant l'entraînement.  \n",
    "\n",
    "En pratique, on utilise 3 sous-dataset, le *training split* que l'on utilise pour l'entraînement du modèle, le *validation split* qui est utilisé pour évaluer le modèle au cours de l'entraînement et le *test split* qui permet d'évaluer le modèle à la fin de l'entraînement et qui est le résultat qui nous importe le plus. \n",
    "\n",
    "Une pratique courante est d'utiliser le split 60-20-20, c'est-à-dire 60% des données pour l'entraînement, 20% pour la validation et 20% pour le test. Cependant, cette recommandation n'est pas pertinente pour toutes les tailles de dataset. En effet, si le dataset contient énormement d'images, on peut prendre moins de données pour la validation et le test. A titre informatif, sur des datasets de plusieurs milliards d'images, on utilise souvent des splits 98-1-1 ou même 99.8-0.1-0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le train et test sont déjà séparé, on va donc séparer le train_dataset en train et validation\n",
    "train_dataset, validation_dataset=torch.utils.data.random_split(dataset, [0.8,0.2])\n",
    "\n",
    "# Création des dataloaders pour séparer en mini-batch automatiquement\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader= DataLoader(validation_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création et entraînement d'un premier modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dans le notebook précédent, nous allons créer un modèle entièrement connecté pour l'entraînement. Comme les données d'entrée sont des images de taille $28 \\times 28$, il est nécessaire de les convertir en vecteur 1D de taille $28 \\times 28=784$ pour les faire passer dans le réseau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) # première couche cachée \n",
    "    self.fc2=nn.Linear(256,256) # seconde couche cachée \n",
    "    self.fc3=nn.Linear(256,10) # couche de sortie\n",
    "    \n",
    "  # La fonction forward est la fonction appelée lorsqu'on fait model(x)\n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28) # Pour convertir l'image de taille 28x28 en tensor de taille 784\n",
    "    x=F.relu(self.fc1(x)) # le F.relu permet d'appliquer la fonction d'activation ReLU sur la sortie de notre couche \n",
    "    x=F.relu(self.fc2(x))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Nombre de paramètres 269322\n"
     ]
    }
   ],
   "source": [
    "model = mlp()\n",
    "print(model)\n",
    "print(\"Nombre de paramètres\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de perte "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la fonction de perte, on utilise la *cross entropy loss* de pytorch qui correspond à la fonction de perte de la régression logistique mais pour un nombre de classes supérieur à 2.  \n",
    "La fonction de perte s'écrit comme ça :  \n",
    "$\\text{Cross Entropy Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{ic} \\log(p_{ic})$  \n",
    "où $N$ est le nombre d'exemple dans le *mini-batch*, $C$ est le nombre de classes, $y_{ic}$ est la valeur cible ($1$ si l'exemple appartient à la classe $c$ et $0$ sinon) et $p_{ic}$ est la prédiction de la probabilité d'appartenance à la classe $c$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En pytorch\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamètres et entraînement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du modèle (peut durer quelques minutes en fonction de la puissance de votre ordinateur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.29076647758483887\n",
      "step 0 val loss 0.15385286509990692\n",
      "step 1 train loss 0.10695428401231766\n",
      "step 1 val loss 0.10097559541463852\n",
      "step 2 train loss 0.07086848467588425\n",
      "step 2 val loss 0.09286081790924072\n",
      "step 3 train loss 0.05028771981596947\n",
      "step 3 val loss 0.08867377787828445\n",
      "step 4 train loss 0.04254501312971115\n",
      "step 4 val loss 0.0835222601890564\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification du modèle sur les données de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le modèle est entraîné, on peut regarder ses performances sur notre \"testing split\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.69\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle obtient une très bonne précision en phase de test ce qui est bon signe.  \n",
    "Cependant, on peut remarquer que, lors de l'entraînement, le loss de training est plus bas que le loss de validation. C'est un point important à considérer. Cela signifie que le modèle est en léger \"overfitting\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting et underfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un élément clé de l'apprentissage profond est la capacité du modèle à ne pas **overfit** les données d'entraînement. L'**overfitting** correspond à un modèle qui aurait trop bien appris sur les données d'entraînement mais qui ne serait pas capable de généraliser à de nouveaux élèments issus de la même distribution.  \n",
    "Pour comprendre le principe, voici une figure faisant la différence entre **underfitting** (modèle trop simple incapable d'apprendre la complexité des données), modèle bien entrainé et **overfitting**.  \n",
    "\n",
    "<img src=\"images/overfitting.png\" alt=\"overfitting\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas le plus critique de l'**overfitting**, le modèle a une précision presque parfaite sur les données d'entraînement mais est mauvais sur les données de validation et de test.  \n",
    "Dans ce cours, nous allons introduire 2 méthodes permettant d'éviter ce problème d'**overfitting**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régularisation L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régularisation L2 est une méthode qui consiste à ajouter une pénalité à la perte basée sur la valeur des poids du modèle. Cette pénalité est proportionnelle au carré des valeurs des poids du modèle (à noter qu'il existe aussi la régularisation L1 qui est linéairement proportionnelle au valeurs des poids du modèle). Cette pénalité encourage les poids du modèle à rester petits et moins sensibles au bruit des données d'entraînement.  \n",
    "On peut formuler la régularisation L2 de cette manière :  \n",
    "$L(w) = L_0(w) + \\lambda \\sum_{i=1}^{n} w_i^2$ où $L(w)$ est la perte régularisée, $L_0(w)$ est la fonction de perte classique, $\\lambda$ est le coefficient de régularisation et $w_i$ est un poids du modèle.  \n",
    "Pour en apprendre plus sur la régularisation L2, vous pouvez consulter le [cours bonus sur la régularisation](../Bonus_CoursSpécifiques/06_Regularisation.ipynb) ou ce [blogpost](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faisons à nouveau notre entraînement mais en ajoutant la régularisation. En pytorch, la régularisation s'utilise en ajoutant le paramètre weight_decay à notre optimizer. La valeur de *weight_decay* correspond au $\\lambda$ de l'équation précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.2986273467540741\n",
      "step 0 val loss 0.1439662128686905\n",
      "step 1 train loss 0.11165566742420197\n",
      "step 1 val loss 0.10781095176935196\n",
      "step 2 train loss 0.07492929697036743\n",
      "step 2 val loss 0.09555892646312714\n",
      "step 3 train loss 0.05378309637308121\n",
      "step 3 val loss 0.08672302216291428\n",
      "step 4 train loss 0.041800014674663544\n",
      "step 4 val loss 0.0883878618478775\n"
     ]
    }
   ],
   "source": [
    "model_with_reg=mlp()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_reg.parameters(),lr=learning_rate,weight_decay=1e-5)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_reg(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_reg(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.73\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_reg(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La différence n'est pas flagrante mais on constaste une diminution de la différence entre la perte de validation et la perte d'entraînement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition** : La régularisation L2 fonctionne parce qu'en pénalisant les grands coefficients, elle favorise des solutions où les poids sont répartis de manière plus uniforme, ce qui réduit la sensibilité du modèle aux variations spécifiques des données d'entraînement et améliore ainsi la robustesse et la généralisation du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre méthode de régularisation est le *dropout*. Cette méthode consiste à désactiver aléatoirement un pourcentage de neurones dans le réseau à chaque étape de l'entraînement (les poids désactivés changent pendant l'entraînement). Chaque neurone d'une couche a une probabilité $p$ d'être desactivé.\n",
    "\n",
    "Cette technique force le réseau à ne pas se reposer sur certains neurones mais plutôt à apprendre des representations plus robuste et qui généralisent mieux. On peut voir le *dropout* comme une sorte d'ensemble de modèles où chaque modèle est différent (car certains neurones sont désactivés) et lors de la phase de test, on prend la \"moyenne\" de ces différents modèles. Lors de la phase de test, le *dropout* est désactivé. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour appliquer le dropout, il est nécessaire de l'ajoute directement dans l'architecture du réseau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_dropout(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) \n",
    "    self.dropout1 = nn.Dropout(0.2) # on désactive 20% des neurones aléatoirement\n",
    "    self.fc2=nn.Linear(256,256) \n",
    "    self.dropout2 = nn.Dropout(0.2) # on désactive 20% des neurones aléatoirement\n",
    "    self.fc3=nn.Linear(256,10) \n",
    "  \n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28)\n",
    "    x=F.relu(self.dropout1(self.fc1(x)))\n",
    "    x=F.relu(self.dropout2(self.fc2(x)))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.3267715573310852\n",
      "step 0 val loss 0.19353896379470825\n",
      "step 1 train loss 0.13504144549369812\n",
      "step 1 val loss 0.14174170792102814\n",
      "step 2 train loss 0.10012412816286087\n",
      "step 2 val loss 0.13484247028827667\n",
      "step 3 train loss 0.07837768644094467\n",
      "step 3 val loss 0.10895466059446335\n",
      "step 4 train loss 0.0631122887134552\n",
      "step 4 val loss 0.10599609464406967\n"
     ]
    }
   ],
   "source": [
    "model_with_dropout=mlp_dropout()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_dropout.parameters(),lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_dropout(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_dropout(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  96.96\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_dropout(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate à nouveau une légère amélioration du résultat de l'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition** : Le *dropout* améliore la généralisation en désactivant aléatoirement des neurones pendant l'entraînement, ce qui empêche le modèle de trop se fier à certains neurones et force une distribution plus robuste et diversifiée des caractéristiques apprises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre technique d'amélioration de l'entraînement d'un réseau de neurones est la *Batch Normalization* (*BatchNorm*). Le principe est de normaliser les entrées de chaque couche d'une réseau avec une distribution avec une moyenne nulle et une variance de 1.  \n",
    "La normalisation s'effectue sur le *batch* complet de la manière suivante :  \n",
    "\n",
    "Pour un *mini-batch* $B$ avec activations $x$ :\n",
    "\n",
    "$\\mu_B = \\frac{1}{m} \\sum_{i=1}^m x_i$ la moyenne des activations $x_i$ des m éléments \n",
    "\n",
    "\n",
    "$\\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i - \\mu_B)^2$ la variance des activations $x_i$ des m éléments \n",
    "\n",
    "\n",
    "$\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$ la valeur de $x_i$ normalisée\n",
    "\n",
    "\n",
    "$y_i = \\gamma \\hat{x}_i + \\beta$ l'ajout des paramètres $\\gamma $ et $\\beta$ permettre au réseau d'apprendre les distributions d'activation optimales.  \n",
    "\n",
    "\n",
    "où $m$ est la taille du *mini-batch* $B$, $\\epsilon$ est une petite constante ajoutée pour éviter la division par zéro, et $\\gamma $ et $\\beta$ sont des paramètres apprenables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pratique, on constate 4 principaux avantages lors de l'utilisation de la *BatchNorm*. \n",
    "- **Accéleration de l'entraînement** : La normalisation des entrées de chaque couche permet d'utiliser un learning rate plus élévé et donc d'accélèrer la convergence de l'entraînement.\n",
    "- **Réduction de la sensibilité à l'initialisation des poids** : La *BatchNorm* permet de stabiliser la distribution des activations ce qui rend le réseau moins sensible à l'initialisation des poids. \n",
    "- **Amélioration de la généralisation** : Comme le dropout et la régularisation l2, la *BatchNorm* agit comme une forme de régularisation. Cela est dû au bruit induit par le fait de normaliser sur le batch.\n",
    "- **Réduction du \"Internal Covariate Shift\"** : La stabilisation des activations tout au long du réseau permet de réduire le changement des distributions des couches internes ce qui facilite l'apprentissage.   \n",
    "\n",
    "Ce qu'il faut retenir c'est que la *BatchNorm* offre de nombreux avantages et il est donc conseillé de l'utiliser systématiquement.   \n",
    "\n",
    "Il existe également d'autres techniques de normalisation comme la *LayerNorm*, la *InstanceNorm*, la *GroupNorm* et d'autres ...  \n",
    "Pour en apprendre plus sur la *batch normalization*, vous pouvez faire le [cours bonus sur la *batch norm*](../Bonus_CoursSpécifiques/02_BatchNorm.ipynb), lire le [papier](https://arxiv.org/pdf/1502.03167) ou le [blogpost](https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739).   \n",
    "Pour avoir des informations supplémentaires sur l'intêret de la normalisation pour l'entraînement des réseaux de neurones, vous pouvez consulter le [blogpost](https://medium.com/nerd-for-tech/overview-of-normalization-techniques-in-deep-learning-e12a79060daf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour implémenter la *BatchNorm* en pytorch, il faut l'ajouter directement dans la construction de notre modèle. A noter qu'on applique souvent la *BatchNorm* avant la fonction d'activation mais que les deux approches sont possibles (avant ou après). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_bn(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) \n",
    "    self.bn1=nn.BatchNorm1d(256) # Batch Normalization\n",
    "    self.fc2=nn.Linear(256,256) \n",
    "    self.bn2=nn.BatchNorm1d(256) # Batch Normalization\n",
    "    self.fc3=nn.Linear(256,10) \n",
    "  \n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28)\n",
    "    x=F.relu(self.bn1(self.fc1(x)))\n",
    "    x=F.relu(self.bn1(self.fc2(x)))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.20796926319599152\n",
      "step 0 val loss 0.1327729970216751\n",
      "step 1 train loss 0.09048832952976227\n",
      "step 1 val loss 0.10177803039550781\n",
      "step 2 train loss 0.0635765939950943\n",
      "step 2 val loss 0.09861738979816437\n",
      "step 3 train loss 0.045849185436964035\n",
      "step 3 val loss 0.09643400460481644\n",
      "step 4 train loss 0.0397462323307991\n",
      "step 4 val loss 0.08524414896965027\n"
     ]
    }
   ],
   "source": [
    "model_with_bn=mlp_bn()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_bn.parameters(),lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_bn(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_bn(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.19\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_bn(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir, la *BatchNorm* permet d'obtenir un meilleur score sur nos données dans les mêmes conditions d'entraînement. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
