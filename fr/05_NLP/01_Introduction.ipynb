{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction au NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu'est-ce que le NLP ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le NLP, ou traitement automatique du langage naturel (Natural Language Processing), est un domaine clé en machine learning. Il couvre diverses tâches liées au texte, comme la traduction, la compréhension de texte, les systèmes de questions/réponses, et bien d'autres.\n",
    "\n",
    "![NLP](./images/applicationsNLP.png)\n",
    "\n",
    "*Figure extraite du [blogpost](https://eastgate-software.com/top-8-applications-of-natural-language-processing-nlp/).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le NLP se distingue dans le deep learning car il traite des données discrètes, généralement lues de gauche à droite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenu du cours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce cours se concentre principalement sur la prédiction du prochain token, en commençant par la prédiction du prochain caractère pour simplifier. Ce problème est à la base des modèles de langage (comme GPT, Llama, Gemini, etc.).\n",
    "\n",
    "L'objectif est de prédire le mot suivant en fonction des mots précédents, avec un contexte plus ou moins étendu selon la méthode et la puissance du modèle. Le contexte est défini par le nombre de tokens (ou mots) utilisés pour cette prédiction.\n",
    "\n",
    "*Qu'est-ce qu'un token ?* Un token est un élément d'entrée du modèle. Il peut s'agir d'un caractère, d'un groupe de caractères ou d'un mot, converti en vecteur avant d'être fourni en entrée au modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspirations pour le cours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce cours s'inspire largement de la série de [vidéos d'Andrej Karpathy](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) ([lien du dépôt GitHub](https://github.com/karpathy/nn-zero-to-hero)), notamment des cours \"building makemore\". Nous proposons ici une version écrite et en français de ces enseignements. Je vous encourage à regarder cette série de vidéos, qui est l'un des meilleurs cours sur les modèles de langage disponibles à ce jour (et gratuit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous structurerons ce cours en plusieurs notebooks, avec des modèles de difficulté croissante. L'idée est de comprendre les limites de chaque modèle avant de passer à un modèle plus complexe.\n",
    "\n",
    "Voici le plan du cours :\n",
    "- Cours 1 : Bigramme (méthode classique et réseaux de neurones)\n",
    "- Cours 2 : Prédiction du prochain mot avec un réseau fully connected\n",
    "- Cours 3 : WaveNet (architecture hiérarchique)\n",
    "- Cours 4 : RNN (réseaux de neurones récurrents avec architecture séquentielle)\n",
    "- Cours 5 : LSTM (réseau récurrent \"amélioré\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note* : Le [cours 7](https://github.com/SimonThomine/CoursDeepLearning/tree/main/07_Transformers) sur les transformers aborde le même problème de génération du prochain caractère, mais avec une architecture transformer et sur un dataset plus complexe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération du dataset prenom.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cours, nous utilisons un dataset de prénoms contenant environ 30 000 des prénoms les plus courants en France depuis 1900 (données de l'INSEE). Le fichier `prenoms.txt` est déjà présent dans le dossier, il n'est donc pas nécessaire d'exécuter le code ci-dessous. Si vous souhaitez le faire, vous devez d'abord télécharger le fichier `nat2022.csv` sur le [site de l'INSEE](https://www.insee.fr/fr/statistiques/7633685?sommaire=7635552).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement du fichier CSV\n",
    "df = pd.read_csv('nat2022.csv', sep=';')\n",
    "\n",
    "# On enlève la catégorie '_PRENOMS_RARES' qui regroupe les prénoms peu fréquents\n",
    "df_filtered = df[df['preusuel'] != '_PRENOMS_RARES']\n",
    "\n",
    "# Pour compter, on fait la somme des nombres de naissances pour chaque prénom\n",
    "df_grouped = df_filtered.groupby('preusuel', as_index=False)['nombre'].sum()\n",
    "\n",
    "# On va trier les prénoms par popularité\n",
    "df_sorted = df_grouped.sort_values(by='nombre', ascending=False)\n",
    "\n",
    "# On extrait les 30 000 prénoms les plus populaires\n",
    "top_prenoms = df_sorted['preusuel'].head(30000).values\n",
    "\n",
    "with open('prenoms.txt', 'w', encoding='utf-8') as file:\n",
    "  for prenom in top_prenoms:\n",
    "    file.write(f\"{prenom}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le notebook suivant, nous commencerons par analyser le dataset (caractères distincts, etc.).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
