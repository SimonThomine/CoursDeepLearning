{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage par transfert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'apprentissage par transfert est une technique courante en deep learning. Elle consiste à réutiliser les poids d'un réseau préentraîné comme base pour former un nouveau modèle.\n",
    "\n",
    "Voici ses principaux avantages :\n",
    "- L'entraînement est plus rapide si les tâches sont similaires.\n",
    "- Les performances sont meilleures qu'avec un modèle entraîné de zéro.\n",
    "- On a besoin de moins de données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![transferlearning](./images/transferlearning.png)\n",
    "\n",
    "Figure extraite de ce [article](https://www.techtarget.com/searchcio/definition/transfer-learning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage par transfert ou ajustement fin ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux termes sont souvent confondus car ils sont très proches. En pratique, l'ajustement fin est une forme d'apprentissage par transfert qui consiste à réentraîner seulement une partie des couches du modèle réutilisé.\n",
    "\n",
    "Voici les définitions claires :\n",
    "- **Apprentissage par transfert** : Entraîner un modèle en utilisant les poids d'un modèle préentraîné sur une autre tâche (on peut réentraîner tout le modèle ou seulement certaines couches).\n",
    "- **Ajustement fin** : Réentraîner certaines couches (souvent les dernières) d'un modèle préentraîné pour l'adapter à une nouvelle tâche.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment utiliser l'ajustement fin ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ajustement fin consiste à réentraîner certaines couches d'un modèle préentraîné pour l'adapter à une nouvelle tâche. Il faut donc choisir le nombre de couches à réentraîner.\n",
    "\n",
    "Comment choisir ce nombre de couches ? Il n'y a pas de formule fixe. On se base généralement sur notre intuition et sur ces règles :\n",
    "- Moins on a de données, moins on réentraîne de couches (peu de données = seulement la dernière couche ; beaucoup de données = presque toutes les couches).\n",
    "- Plus les tâches sont similaires, moins on réentraîne de couches (ex. : détecter des hamsters en plus des chats, chiens et lapins ; détecter des maladies à partir d'un modèle chat/chien/lapin est très différent).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quand utiliser l'apprentissage par transfert ou l'ajustement fin ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En général, utiliser un modèle préentraîné comme base est toujours bénéfique (sauf si les domaines sont très différents). Je vous conseille de l'utiliser dès que possible.\n",
    "\n",
    "Cependant, cela impose quelques contraintes :\n",
    "- L'architecture du modèle ne peut plus être modifiée comme on le souhaite (les couches non réentraînées).\n",
    "- Il faut disposer des poids d'un modèle préentraîné (on en trouve beaucoup en ligne, cf [cours 6 sur HuggingFace](../06_HuggingFace/README.md)).\n",
    "\n",
    "**Note** : Pour la classification d'images, on utilise souvent un modèle préentraîné sur [ImageNet](https://www.image-net.org/) car ses 1000 classes rendent le modèle assez généraliste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset d'entraînement : comment faire ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'ajustement fin d'un modèle, on peut avoir deux objectifs :\n",
    "- **Cas 1** : Entraîner un modèle sur une tâche complètement différente de celle pour laquelle il a été préentraîné (ex. : classifier des dinosaures alors que le modèle est entraîné sur des mammifères). Dans ce cas, le modèle peut \"oublier\" sa tâche d'origine sans que cela pose problème.\n",
    "- **Cas 2** : Entraîner un modèle sur une tâche complémentaire à celle pour laquelle il a été préentraîné (ex. : détecter des oiseaux tout en restant performant sur les mammifères). Dans ce cas, on veut que le modèle reste performant sur la tâche d'origine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon le cas, on n'utilise pas les mêmes données pour l'entraînement. Pour le **cas 1**, le dataset ne contient que les nouvelles images à classifier (ex. : uniquement des dinosaures). Pour le **cas 2**, on inclut des données de l'ancien et du nouveau dataset pour que le modèle reste performant sur les anciennes données. En général, on prend 50/50, mais cela peut varier (ex. : moitié mammifères, moitié oiseaux).\n",
    "\n",
    "**Note** : Selon ce principe, le vrai open-source signifie qu'on rend accessibles le code, les poids et les données d'entraînement du modèle. Sans ces trois éléments, on ne peut pas ajuster finement le modèle efficacement. C'est particulièrement vrai pour les modèles de langage LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modèles de base sont entraînés sur de grandes quantités de données (souvent non labelisées) et servent de base pour l'ajustement fin ou l'apprentissage par transfert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèles de base pour le NLP** : Pour le NLP, il existe de nombreux modèles de base comme GPT, BLOOM, Llama, Gemini, etc. Ces modèles sont ajustés finement pour diverses tâches. Par exemple, chatGPT est une version ajustée finement de GPT pour les conversations de type chatbot.\n",
    "\n",
    "**Modèles de base pour les images** : Pour les images, le terme modèle de base est débattu car ce n'est pas aussi évident que pour le NLP. On peut citer ViT, DINO, CLIP, etc.\n",
    "\n",
    "**Modèles de base pour le son** : Pour le son, le modèle CLAP est un exemple de modèle de base.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
