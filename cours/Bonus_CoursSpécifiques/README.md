# üåü Cours sp√©cifiques üåü
Ce cours pr√©sente des concepts tr√®s int√©ressant √† comprendre mais non essentiels dans une pratique courante du deep learning. Si vous √™tes int√©ress√© par comprendre le fonctionnement d'un r√©seau de neurones de mani√®re plus approfondie et de d√©couvrir la raison de l'utilisation de techniques comme la BatchNorm, les connexions r√©siduelles, les optimizers, le dropout, la data augmentation etc ..., ce cours est fait pour vous !

## Notebook 1Ô∏è‚É£ : [Activation et initialisation](01_ActivationEtInitialisation.ipynb)
Ce notebook pr√©sente les consid√©rentions importantes √† prendre en compte lors de l'initialisation d'un r√©seau de neurones.

## Notebook 2Ô∏è‚É£ : [BatchNorm](02_BatchNorm.ipynb)
Ce notebook introduit un d√©tail la *batch normalization* en pr√©sentant ses int√™rets et son impl√©mentation.

## Notebook 3Ô∏è‚É£ : [Data augmentation](03_DataAugmentation.ipynb)
Ce notebook pr√©sente la *data augmentation* et son utilit√© pour l'entra√Ænement des r√©seaux de neurones.

## Notebook 4Ô∏è‚É£ : [Broadcasting](04_Broadcasting.ipynb)
Ce notebook pr√©sente les *broadcasting rules* de pytorch qui sont des r√®gles sur la manipulation des tenseurs torch. Ces r√®gles sont tr√®s importantes √† ma√Ætriser.

## Notebook 5Ô∏è‚É£ : [Optimizer](05_Optimizer.ipynb)
Ce notebook d√©crit les diff√©rents *optimizer* utilisables pour entra√Æner un r√©seau de neurones.

## Notebook 6Ô∏è‚É£ : [R√©gularisation](06_Regularisation.ipynb)
Ce notebook pr√©sente en d√©tails deux m√©thodes de r√©gularisation : le r√©gularisation L2 et le *dropout.*

## Notebook 7Ô∏è‚É£ : [Connexions R√©siduelles](07_ConnexionsResiduelles.ipynb)
Ce notebook introduit les connexions r√©siduelles et leurs utilit√©s pour l'entra√Ænement de r√©seaux de neurones profonds.

## Notebook 8Ô∏è‚É£ : [CrossValidation](08_CrossValidation.ipynb)
Ce notebook introduit la m√©thode de cross validation pour √©valuer les mod√®les et d√©tecter l'overfitting.

## Notebook 9Ô∏è‚É£ : [Metriques Evaluation](09_MetriquesEvaluation.ipynb)
Ce notebook introduit diff√©rents m√©triques que l'on peut utiliser pour √©valuer son mod√®le.

## Notebook 1Ô∏è‚É£0Ô∏è‚É£ : [Tokenization](10_Tokenization.ipynb)
Ce notebook introduit la *tokenization* en expliquant le fonctionnement, les limitations et en proposant une impl√©mentation du *byte-pair encoding*.

## Notebook 1Ô∏è‚É£1Ô∏è‚É£ : [Quantization](11_Quantization.ipynb)
Ce notebook introduit la quantization et les m√©thodes de fine-tuning de mod√®les LLM. La premi√®re partie d√©crit les diff√©rentes forme de quantization et la th√©orie derri√®re. La derni√®re partie introduit les m√©thodes LoRA et QLoRA pour le fine-tuning.