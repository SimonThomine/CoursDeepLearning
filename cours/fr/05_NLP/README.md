# üó®Ô∏è NLP üó®Ô∏è
Ce cours est grandement inspir√© de la s√©rie de vid√©o de Andrej Karpathy ["Building makemore"](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) qui tra√Æte les NLP avec une approche de pr√©diction du prochain token. Le cours aborde d'abord des mod√®les tr√®s simples pour avoir une intuition sur le tra√Ætement de donn√©es discr√®tes avec un r√©seau neurones puis les mod√®les se complexifient petit √† petit. 

## Notebook 1Ô∏è‚É£ : [Introduction](01_Introduction.ipynb)
Ce notebook introduit le concept de *natural language processing* (NLP), d√©crit le cours √† venir et construit un dataset que l'on utilisera dans les notebooks suivants.

## Notebook 2Ô∏è‚É£ : [Bigramme](02_bigramme.ipynb)
Ce notebook introduit l'architecture bigramme pour la pr√©diction du prochain caract√®re dans un objectif de g√©n√©ration de pr√©noms.

## Notebook 3Ô∏è‚É£ : [R√©seau Fully Connected](03_R√©seauFullyConnected.ipynb)
Ce notebook impl√©mente l'architecture d'un article scientifique utilisant un r√©seau fully connected pour la pr√©dication du prochain caract√®re.

## Notebook 4Ô∏è‚É£ : [WaveNet](04_WaveNet.ipynb)
Ce notebook impl√©mente l'architecture d'un article scientifique utilisant un wavenet pour la pr√©diction du prochain caract√®re.

## Notebook 5Ô∏è‚É£ : [RNN](05_Rnn.ipynb)
Ce notebook pr√©sente le concept de r√©seau de neurones r√©currents et propose une impl√©mentation d'un r√©seau de neurones r√©currents pour la pr√©diction du prochain caract√®re √† partir des pi√®ces de Moli√®re.

## Notebook 6Ô∏è‚É£ : [LSTM](06_Lstm.ipynb)
Ce notebook introduit l'architecture *long short-term memory* (LSTM) et l'impl√©mente en pytorch pour la pr√©diction du prochain caract√®re.