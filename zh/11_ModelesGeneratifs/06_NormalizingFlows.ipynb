{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 归一化流\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本课程将介绍**归一化流**，一种用于*表示学习*的生成模型。虽然不如 VAE、GAN 或扩散模型知名，但它们仍具有多项优势。\n",
    "\n",
    "GAN 和 VAE 无法精确评估概率分布。GAN 完全无法做到这一点，而 VAE 则使用[证据下界（ELBO）](https://deepgenerativemodels.github.io/notes/vae/)近似。这在训练过程中会带来问题：VAE 生成的图像常常模糊，而 GAN 则可能陷入*模式崩溃*（mode collapse）。\n",
    "\n",
    "归一化流为这些问题提供了解决方案。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工作原理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归一化流**是由一系列**可逆变换**（双射）组成的模型。其核心思想是将复杂的数据分布（如图像）通过连续变换，逐步映射为简单的已知分布（如标准正态分布 $N(0,1)$）。\n",
    "\n",
    "训练过程通过**最大化数据似然**实现，即最小化真实数据概率密度的*负对数似然*（$-\\log p(x)$）。通过优化变换参数，使生成分布与目标分布尽可能接近。\n",
    "\n",
    "![归一化流示意图](./images/NFlow.png)\n",
    "*图片来源：[归一化流入门博文](https://towardsdatascience.com/introduction-to-normalizing-flows-d002af262a4b)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优势与局限\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**优势**：\n",
    "- 训练过程**非常稳定**，不易发散\n",
    "- 比 GAN 或 VAE **更易收敛**\n",
    "- 生成数据时**无需引入噪声**\n",
    "\n",
    "**局限**：\n",
    "- **表达能力**不如 GAN 或 VAE 强\n",
    "- 由于需满足**双射性**和**体积保持**，潜在空间维度高且**难以解释**\n",
    "- 生成结果的**质量**通常低于 GAN 或 VAE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注**：归一化流背后有深刻的理论基础，但本课程不展开详述。如需深入了解，可参考斯坦福大学 CS236 课程的[相关笔记](https://deepgenerativemodels.github.io/notes/flow/)。\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
