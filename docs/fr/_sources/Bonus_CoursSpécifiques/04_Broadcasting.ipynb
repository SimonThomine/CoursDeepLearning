{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le *broadcasting* est un mécanisme utilisé par PyTorch pour traiter les tenseurs lors d'opérations arithmétiques non évidentes.\n",
    "\n",
    "Par exemple, il est clair qu'on ne peut pas additionner une matrice $3 \\times 3$ avec une matrice $4 \\times 2$, ce qui entraînerait une erreur. En revanche, ajouter un scalaire à une matrice $3 \\times 3$ ou un vecteur de taille $3$ à une matrice $3 \\times 3$ est possible, même si la logique n'est pas toujours évidente.\n",
    "\n",
    "Le [broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html) de PyTorch repose sur des règles simples à connaître lors de la manipulation de tenseurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Règles de broadcasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour que deux tenseurs soient *broadcastables*, ils doivent respecter les règles suivantes :\n",
    "- Chaque tenseur doit avoir au moins une dimension.\n",
    "- En itérant sur les tailles des dimensions (en commençant par la dernière), les tailles doivent être égales, ou l'une d'elles doit être 1, ou l'une d'elles doit être absente.\n",
    "\n",
    "Utilisons des exemples pour clarifier :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Deux tenseurs de la même taille sont toujours broadcastables\n",
    "x=torch.zeros(5,7,3)\n",
    "y=torch.zeros(5,7,3)\n",
    "\n",
    "# Les deux tenseurs suivants ne sont pas broadcastables car x n'a pas au moins une dimension\n",
    "x=torch.zeros((0,))\n",
    "y=torch.zeros(2,2)\n",
    "\n",
    "# On aligne les dimensions visuellement pour voir si les tenseurs sont broadcastables\n",
    "# En partant de la droite,\n",
    "# 1. x et y ont la même taille et sont de taille 1\n",
    "# 2. y est de taille 1\n",
    "# 3. x et y ont la même taille\n",
    "# 4. la dimension de y n'existe pas\n",
    "# Les deux tenseurs sont donc broadcastables\n",
    "x=torch.zeros(5,3,4,1)\n",
    "y=torch.zeros(  3,1,1)\n",
    "\n",
    "# A l'inverse, ces deux tenseurs ne sont pas broadcastables car 3. x et y n'ont pas la même taille\n",
    "x=torch.zeros(5,2,4,1)\n",
    "y=torch.zeros(  3,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous savons comment identifier deux tenseurs *broadcastables*, définissons les règles appliquées lors de l'opération entre eux.\n",
    "\n",
    "Les règles sont :\n",
    "- **Règle 1** : Si le nombre de dimensions de x et y diffère, ajoutez 1 au début des dimensions du tenseur ayant le moins de dimensions pour les aligner.\n",
    "- **Règle 2** : Pour chaque taille de dimension, la taille résultante est le maximum des tailles de x et y.\n",
    "\n",
    "Le tenseur dont la taille est modifiée sera dupliqué autant que nécessaire pour correspondre.\n",
    "\n",
    "**Note** : Si deux tenseurs ne sont pas *broadcastables*, leur addition entraînera une erreur. Cependant, dans de nombreux cas, le *broadcasting* fonctionnera mais ne produira pas le résultat souhaité. C'est pourquoi il est crucial de maîtriser ces règles.\n",
    "\n",
    "Reprenons nos deux exemples :\n",
    "\n",
    "Ajouter un scalaire à une matrice $3 \\times 3$ :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :  tensor([[ 0.6092, -0.6887,  0.3060],\n",
      "        [ 1.3496,  1.7739, -0.4011],\n",
      "        [-0.8876,  0.7196, -0.3810]])\n",
      "y :  tensor(1)\n",
      "x+y :  tensor([[1.6092, 0.3113, 1.3060],\n",
      "        [2.3496, 2.7739, 0.5989],\n",
      "        [0.1124, 1.7196, 0.6190]])\n",
      "x+y shape :  torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,3)\n",
    "y=torch.tensor(1)\n",
    "print(\"x : \" ,x)\n",
    "print(\"y : \" ,y)\n",
    "print(\"x+y : \" ,x+y)\n",
    "print(\"x+y shape : \",(x+y).shape)\n",
    "# Le tenseur y est broadcasté pour avoir la même taille que x, il se transforme en tenseur de 1 de taille 3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter un vecteur de taille $3$ à une matrice $3 \\times 3$ :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :  tensor([[ 0.9929, -0.1435,  1.5740],\n",
      "        [ 1.2143,  1.3366,  0.6415],\n",
      "        [-0.2718,  0.3497, -0.2650]])\n",
      "y :  tensor([1, 2, 3])\n",
      "x+y :  tensor([[1.9929, 1.8565, 4.5740],\n",
      "        [2.2143, 3.3366, 3.6415],\n",
      "        [0.7282, 2.3497, 2.7350]])\n",
      "x+y shape :  torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,3)\n",
    "y=torch.tensor([1,2,3]) # tenseur de taille 3\n",
    "print(\"x : \" ,x)\n",
    "print(\"y : \" ,y)\n",
    "print(\"x+y : \" ,x+y)\n",
    "print(\"x+y shape : \",(x+y).shape)\n",
    "# Le tenseur y est broadcasté pour avoir la même taille que x, il se transforme en tenseur de 1 de taille 3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons maintenant d'autres exemples plus complexes :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y shape :  torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "x=torch.zeros(5,3,4,1)\n",
    "y=torch.zeros(  3,1,1)\n",
    "print(\"x+y shape : \",(x+y).shape)\n",
    "# Le tenseur y a été étendu en taille 1x3x1x1 (règle 1) puis dupliqué en taille 5x3x4x1 (règle 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y shape :  torch.Size([3, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "x=torch.empty(1)\n",
    "y=torch.empty(3,1,7)\n",
    "print(\"x+y shape : \",(x+y).shape)\n",
    "# Le tenseur y a été étendu en taille 1x1x1 (règle 1) puis dupliqué en taille 3x1x7 (règle 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx+y shape : \u001b[39m\u001b[38;5;124m\"\u001b[39m,(\u001b[43mx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43my\u001b[49m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# L'opération n'est pas possible car les tenseurs ne sont pas broadcastables (dimension 3 en partant de la fin ne correspond pas)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "x=torch.empty(5,2,4,1)\n",
    "y=torch.empty(3,1,1)\n",
    "print(\"x+y shape : \",(x+y).shape)\n",
    "# L'opération n'est pas possible car les tenseurs ne sont pas broadcastables (dimension 3 en partant de la fin ne correspond pas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres points à considérer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison avec des scalaires\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On n'y pense pas toujours, mais cela permet d'effectuer des comparaisons de manière simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False])\n",
      "tensor([False,  True, False])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([10., 0, -4])\n",
    "print(a > 0)\n",
    "print(a==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi comparer deux tenseurs entre eux :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True, False])\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor([False,  True, False])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([4,2,6])\n",
    "# Comparaison élément par élément\n",
    "print(a==b)\n",
    "# Comparaison élément par élément et égalité pour tous les éléments\n",
    "print((a==b).all())\n",
    "# Comparaison élément par élément et égalité pour au moins un élément\n",
    "print((a==b).any())\n",
    "# Comparaison avec supérieur ou égal\n",
    "print(a>=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela peut être très utile pour créer des masques à partir d'un seuil, par exemple, ou vérifier que deux opérations sont équivalentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de `unsqueeze()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons vu précédemment qu'il est possible de *broadcaster* un tenseur de taille $3$ vers une matrice de taille $3 \\times 3$. Le *broadcasting* de PyTorch le transforme automatiquement en taille $1 \\times 3$ pour effectuer l'opération. Cependant, on peut vouloir réaliser l'opération dans l'autre sens, c'est-à-dire ajouter un tenseur $3 \\times 1$ à une matrice de taille $3 \\times 3$.\n",
    "\n",
    "Dans ce cas, il faut remplacer la règle 1 manuellement à l'aide de la fonction [unsqueeze()](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html), qui permet d'ajouter une dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y :  tensor([[ 1.3517,  1.1880,  0.4483],\n",
      "        [ 0.5137, -0.5406, -0.1412],\n",
      "        [-0.0108,  1.3757,  0.6112]])\n",
      "x+y :  tensor([[2.3517, 3.1880, 3.4483],\n",
      "        [1.5137, 1.4594, 2.8588],\n",
      "        [0.9892, 3.3757, 3.6112]])\n",
      "x shape :  torch.Size([3, 1])\n",
      "x+y :  tensor([[2.3517, 2.1880, 1.4483],\n",
      "        [2.5137, 1.4594, 1.8588],\n",
      "        [2.9892, 4.3757, 3.6112]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3])\n",
    "y=torch.randn(3,3)\n",
    "print(\"y : \",y )\n",
    "print(\"x+y : \",x+y) \n",
    "\n",
    "x=x.unsqueeze(1)\n",
    "print(\"x shape : \",x.shape)\n",
    "print(\"x+y : \",x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir, nous avons pu contourner les règles de PyTorch pour obtenir le résultat souhaité.\n",
    "\n",
    "**Note** :\n",
    "- La règle 1 de PyTorch équivaut à appliquer *x.unsqueeze(0)* jusqu'à ce que le nombre de dimensions soit le même.\n",
    "- Il est possible de remplacer *unsqueeze()* par *None* de la manière suivante :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3])\n",
    "# La première opération est l'équivalent de unsqueeze(0) et la seconde de unsqueeze(1)\n",
    "x[None].shape,x[...,None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de `keepdim`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions de PyTorch qui réduisent la taille d'un tenseur selon une dimension ([*torch.sum*](https://pytorch.org/docs/stable/generated/torch.sum.html) pour sommer selon une dimension, [*torch.mean*](https://pytorch.org/docs/stable/generated/torch.mean.html) pour calculer la moyenne, etc.) ont un paramètre intéressant à utiliser dans certains cas.\n",
    "\n",
    "Ces opérations modifient la dimension du tenseur et suppriment automatiquement la dimension sur laquelle l'opération a été effectuée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4,5)\n",
    "print(x.shape)\n",
    "x=x.sum(dim=1) # somme sur la dimension 1\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous souhaitez conserver la dimension sur laquelle la somme est effectuée, vous pouvez utiliser l'argument *keepdim=True*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4,5)\n",
    "print(x.shape)\n",
    "x=x.sum(dim=1,keepdim=True) # somme sur la dimension 1\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela peut être très utile pour éviter les erreurs avec les dimensions. Examinons un cas où cela impacte le *broadcasting*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les deux opérations sont elles équivalentes ? : False\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4,5)\n",
    "y=torch.randn(1,1,1)\n",
    "x_sum=x.sum(dim=1)\n",
    "x_sum_keepdim=x.sum(dim=1,keepdim=True)\n",
    "print(\"Les deux opérations sont elles équivalentes ? :\",(x_sum+y==x_sum_keepdim+y).all().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici ce qui s'est passé :\n",
    "- Dans le premier cas, *x_sum* a une taille de $3 \\times 5$. La règle 1 le transforme en $1 \\times 3 \\times 5$, et la règle 2 transforme y en $1 \\times 3 \\times 5$.\n",
    "- Dans le second cas, *x_sum_keepdim* a une taille de $3 \\times 1 \\times 5$, et la règle 2 transforme y en $1 \\times 3 \\times 5$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation d'Einstein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie n'est pas directement liée au *broadcasting*, mais il est important de la connaître.\n",
    "\n",
    "Pour multiplier des matrices dans PyTorch, nous avons utilisé l'opérateur @ (ou *torch.matmul*) jusqu'ici. Il existe une autre méthode pour effectuer des multiplications matricielles avec la *Einstein Summation* ([*torch.einsum*](https://pytorch.org/docs/stable/generated/torch.einsum.html)).\n",
    "\n",
    "Il s'agit d'une notation compacte pour exprimer des produits et des sommes, par exemple :\n",
    "**ik,kj -> ij**\n",
    "Le côté gauche représente les dimensions des entrées, séparées par des virgules. Ici, nous avons deux tenseurs avec chacun deux dimensions (**i,k** et **k,j**). Le côté droit représente les dimensions du résultat, soit un tenseur de dimensions **i,j**.\n",
    "\n",
    "Les règles de la notation d'Einstein sont :\n",
    "- Les indices répétés à gauche sont implicitement sommés s'ils n'apparaissent pas à droite.\n",
    "- Chaque indice peut apparaître au maximum deux fois à gauche.\n",
    "- Les indices non répétés à gauche doivent apparaître à droite.\n",
    "\n",
    "On peut l'utiliser pour diverses opérations :\n",
    "```python\n",
    "torch.einsum('ij->ji', a)\n",
    "```\n",
    "renvoie la transposée de la matrice a.\n",
    "\n",
    "Alors que\n",
    "```python\n",
    "torch.einsum('bi,ij,bj->b', a, b, c)\n",
    "```\n",
    "renvoie un vecteur de taille b où la k-ième coordonnée est la somme de $a[k,i]⋅b[i,j]⋅c[k,j]$. Cette notation est particulièrement pratique lorsque vous manipulez des *batchs* avec plusieurs dimensions.\n",
    "Par exemple, si vous avez deux lots de matrices et que vous voulez calculer le produit matriciel par *batch*, vous pouvez utiliser :\n",
    "```python\n",
    "torch.einsum('bik,bkj->bij', a, b)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est une méthode pratique pour effectuer des multiplications matricielles dans PyTorch. De plus, c'est très rapide et souvent la manière la plus efficace pour réaliser des opérations personnalisées dans PyTorch.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
