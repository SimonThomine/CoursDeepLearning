{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le chapitre précédent, on a découvert plein d'applications de la library Transformers de Hugging Face. Comme son nom l'indique, cette library gère des modèles *transformers*. Mais alors, qu'est-ce qu'un modèle *transformer* ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le transformer, d'où ça vient ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusqu'en 2017, la plupart des réseaux de neurones pour le NLP utilisaient des RNN. En 2017, des chercheurs de Google ont publié un article qui a révolutionné le domaine du NLP, puis plus tard d'autres domaines du deep learning (vision, audio, etc.). Ils ont introduit l'architecture *transformer* dans leur papier [\"Attention Is All You Need\"](https://arxiv.org/pdf/1706.03762).\n",
    "\n",
    "Voici à quoi ressemble l'architecture du *transformer* :\n",
    "\n",
    "![Transformer](./images/transformer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À première vue, ça semble bien compliqué. La partie de gauche s'appelle l'encodeur et celle de droite, le décodeur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenu du cours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première partie : construisons GPT from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première partie de ce cours s'inspire grandement de la vidéo [\"Let's build GPT: from scratch, in code, spelled out.\"](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1806s&ab_channel=AndrejKarpathy) d'Andrej Karpathy. On y implémente un modèle qui prédit le prochain caractère en se basant sur les caractères précédents (un peu comme dans le cours 5 sur le NLP). Cette partie va nous aider à comprendre l'intérêt de l'architecture *transformer*, surtout du côté du décodeur.\n",
    "\n",
    "Dans cette partie, on va entraîner un modèle à écrire du \"Molière\" automatiquement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deuxième partie : Théorie et encodeur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième partie aborde des concepts un peu plus mathématiques et présente aussi le décodeur de l'architecture *transformer*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troisième partie : ViT, BERT et autres architectures marquantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette troisième partie présente rapidement des adaptations de l'architecture *transformer* pour des tâches différentes de GPT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quatrième partie : Implémentation du Vision Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la quatrième partie, on implémente le *vision transformer* à partir du papier [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) et on l'entraîne sur le dataset CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Cinquième partie : Implémentation du Swin Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cinquième et dernière partie propose une explication du papier [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/pdf/2103.14030) ainsi qu'une implémentation simplifiée.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
