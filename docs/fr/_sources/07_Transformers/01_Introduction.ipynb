{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le chapitre précédent, nous avons vu de nombreuses applications de la library transformers de Hugging Face. Comme son nom l'indique, cette library gère des modèles *transformers*. Mais alors, qu'est ce qu'un modèle *transformer* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le transformer, d'où ça vient ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusqu'à 2017, la plupart des réseaux de neurones pour les tâches de NLP utilisaient des réseaux récurrents (RNN). En 2017, des chercheurs de google ont publié un papier qui a changé le domaine du NLP puis plus tard les autres domaines du deep learning (vision, audio etc...) en introduisant l'architecture *transformer*.   \n",
    "\n",
    "Ce papier est [\"Attention Is All You Need\"](https://arxiv.org/pdf/1706.03762) et l'architecture du *transformer* ressemble à cela :   \n",
    "\n",
    "![Transformer](./images/transformer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A première vue, ça semble bien compliqué. La partie de gauche s'appelle l'encodeur et la partie de droite le décodeur.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenu du cours "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première partie : construisons GPT from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première partie de ce cours s'inspire grandement de la vidéo [\"Let's build GPT: from scratch, in code, spelled out.\"](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1806s&ab_channel=AndrejKarpathy) de Andrej Karpathy et consiste à implémenter un modèle de prédiction du prochain caractère en se basant sur les caractères précédents (c'est un peu la continuité du cours 5 sur les NLP). Cette partie va servir à appréhender l'intêret de l'architecture *transformer* et en particulier du décodeur.    \n",
    "Dans cette partie, nous entrainerons un modèle à écrire du \"Molière\" automatiquement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deuxième partie : Théorie et encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième partie présente des concepts un peu plus mathématiques et présente également le décodeur de l'architecture *transformer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troisième partie : ViT, BERT et autres architectures marquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette troisième partie présente rapidement des adaptations de l'architecture *transformer* pour des tâches différente de GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quatrième partie : Implémentation du Vision Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la quatrième partie, nous implémentons le *vision transformer* à partir du papier [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\n",
    "](https://arxiv.org/abs/2010.11929) et nous l'entraînons sur le dataset CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Cinquième partie : Implémentation du Swin Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cinquième et dernière partie propose une explication du papier [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/pdf/2103.14030) ainsi qu'une implémentation simplifiée."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
