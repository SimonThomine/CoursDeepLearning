{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迁移学习\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**迁移学习**是深度学习中的常用技术。它通过重复利用预训练网络的权重作为基础，来训练新模型。\n",
    "\n",
    "其主要优势包括：\n",
    "- 若任务相似，训练速度更快；\n",
    "- 性能优于从零开始训练的模型；\n",
    "- 需要的数据量更少。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![迁移学习示意图](./images/transferlearning.png)\n",
    "\n",
    "图片来源：[《迁移学习》文章](https://www.techtarget.com/searchcio/definition/transfer-learning)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习与微调：区别何在？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两个术语常被混淆，因为它们非常相似。实际上，**微调**是迁移学习的一种形式，仅重新训练模型中被重复利用的部分层。\n",
    "\n",
    "明确定义如下：\n",
    "- **迁移学习**：利用预训练模型的权重（可重新训练整个模型或仅部分层）来训练新任务的模型。\n",
    "- **微调**：仅重新训练预训练模型的部分层（通常是最后几层），以适应新任务。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何进行微调？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微调是通过重新训练预训练模型的部分层，使其适应新任务。关键在于选择**重新训练的层数**。\n",
    "\n",
    "如何选择层数？没有固定公式，通常依赖经验与以下规则：\n",
    "- **数据量越少**，重新训练的层数越少（数据少时仅训练最后一层；数据多时可训练几乎所有层）。\n",
    "- **任务相似度越高**，重新训练的层数越少（例如：在猫/狗/兔的模型基础上增加仓鼠检测，与用该模型检测疾病相比，前者任务更相似）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 何时使用迁移学习或微调？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常，**基于预训练模型**总是有益的（除非领域差异极大）。建议尽可能使用。\n",
    "\n",
    "但需注意以下限制：\n",
    "- 模型架构的**非重训练层**无法随意修改；\n",
    "- 需预先获取预训练模型的权重（可参考[HuggingFace课程](../06_HuggingFace/README.md)获取在线资源）。\n",
    "\n",
    "**注**：在图像分类中，常使用基于[ImageNet](https://www.image-net.org/)（含1000类）预训练的模型，因其通用性强。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练数据集：如何准备？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微调模型时，通常有两种目标：\n",
    "- **情况1**：训练与预训练任务**完全不同**的任务（例如：用训练哺乳动物的模型分类恐龙）。此时模型可“遗忘”原任务，无影响。\n",
    "- **情况2**：训练与预训练任务**互补**的任务（例如：在保持哺乳动物检测性能的同时增加鸟类检测）。此时需确保模型在原任务上保持性能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同情况需采用不同的训练数据：\n",
    "- **情况1**：数据集仅包含**新类别**数据（例如：仅恐龙图像）。\n",
    "- **情况2**：数据集需包含**旧类别**与**新类别**数据（例如：50%哺乳动物 + 50%鸟类），以保持原任务性能。比例可调整。\n",
    "\n",
    "**注**：真正的开源需公开模型的**代码**、**权重**及**训练数据**。缺少任一元素，将难以有效微调，尤以大型语言模型（LLM）为甚。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基础模型**是通过大规模数据（通常为无标签数据）训练而成，用作迁移学习或微调的基础。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **NLP基础模型**：如GPT、BLOOM、Llama、Gemini等，可通过微调适应不同任务。例如，ChatGPT即GPT的微调版本，专用于聊天机器人场景。\n",
    "- **图像基础模型**：概念尚存争议，不如NLP领域明确。常见模型有ViT、DINO、CLIP等。\n",
    "- **音频基础模型**：以CLAP为代表。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
