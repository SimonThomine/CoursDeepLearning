{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter, we explored many applications of the Hugging Face Transformers library. As its name suggests, this library manages *transformer* models. But what exactly is a *transformer* model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origins of the Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until 2017, most neural networks for NLP used RNNs. In 2017, Google researchers published a paper that revolutionized the field of NLP, and later other areas of deep learning (vision, audio, etc.). They introduced the *transformer* architecture in their paper [\"Attention Is All You Need\"](https://arxiv.org/pdf/1706.03762).\n",
    "Here is what the *transformer* architecture looks like:\n",
    "![Transformer](./images/transformer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, this seems quite complex. The left part is called the encoder, and the right part is the decoder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Building GPT from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this course is heavily inspired by Andrej Karpathy's video [\"Let's build GPT: from scratch, in code, spelled out.\"](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1806s&ab_channel=AndrejKarpathy). In this part, we implement a model that predicts the next character based on previous characters (similar to Course 5 on NLP). This will help us understand the benefits of the *transformer* architecture, especially on the decoder side.\n",
    "In this part, we will train a model to automatically write \"Moli√®re.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Theory and Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part covers more mathematical concepts and also introduces the decoder of the *transformer* architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: ViT, BERT, and Other Notable Architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This third part quickly introduces adaptations of the *transformer* architecture for tasks other than GPT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Implementing the Vision Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fourth part, we implement the *vision transformer* based on the paper [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) and train it on the CIFAR-10 dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Part 5: Implementing the Swin Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fifth and final part provides an explanation of the paper [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/pdf/2103.14030) along with a simplified implementation.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
