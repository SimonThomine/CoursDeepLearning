# Deep Learning Course 🚀

Welcome to this comprehensive Deep Learning course! This course will teach you Deep Learning from scratch, with both practical and theoretical approaches.

## 🎯 Course Objectives

- Understand the mathematical foundations of Deep Learning
- Master modern neural network architectures
- Implement models with PyTorch
- Discover practical applications of Deep Learning

## 📚 Course Structure

The course is organized into several parts:

1. **🏗️ Foundations**  
   Introduction to optimization with gradient descent, intuitive understanding of the chain rule, and first steps with logistic regression.

2. **🧠 Fully Connected Networks**  
   Explore how neural networks work using [micrograd](https://github.com/karpathy/micrograd/tree/master) and then with PyTorch. Introduction to advanced training techniques to improve performance.

3. **🖼️ Convolutional Networks**  
   Presentation of convolutional layers and their use in neural networks. Practical examples: classification on MNIST, CIFAR-10, and image segmentation.

4. **🔄 Autoencoders**  
   Discover unsupervised learning with autoencoders: anomaly detection and image denoising.

5. **🗨️ NLP**  
   Introduction to natural language processing inspired by the ["Building makemore"](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) series: from simple models to more complex architectures for text prediction.

6. **🤗 Hugging Face**  
   Explore the [Hugging Face](https://huggingface.co/) platform: discover models, datasets, and libraries (transformers, diffusers, gradio) for various use cases.

7. **🤖 Transformers**  
   In-depth study of the transformer architecture: step-by-step implementation, mathematical explanations, various applications (vision, translation…), and introduction to vision transformers.

8. **🔍 Object Detection (YOLO)**  
   Presentation of object detection methods (two-stage, one-stage), focus on [YOLO](https://arxiv.org/pdf/1506.02640), and use of the [ultralytics](https://www.ultralytics.com/) library.

9. **🎯 Contrastive Training**  
   Introduction to contrastive training: implementation for face verification and applications to unsupervised learning.

10. **🤝 Transfer Learning and Distillation**  
    Concepts of transfer learning and knowledge distillation: practical implementations, distillation for anomaly detection, and LLM finetuning with BERT and Hugging Face.

11. **🌀 Generative Models**  
    Presentation of the main families of generative models: GANs, VAEs, normalizing flows, diffusion models (excluding autoregressive models already covered in NLP/Transformers).

12. **🌟 Bonus – Specific Topics**  
    Advanced concepts and complementary techniques: BatchNorm, residual connections, optimizers, dropout, data augmentation, etc.

## 🛠️ Prerequisites

- Basic knowledge of Python
- Some mathematics (linear algebra, calculus)
- Motivation to learn! 💪

*Start your learning journey by exploring the foundations of Deep Learning!*