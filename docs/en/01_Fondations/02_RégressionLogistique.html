
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Logistic Regression &#8212; Deep Learning Course</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '01_Fondations/02_RÃ©gressionLogistique';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="My First Neural Network" href="../02_R%C3%A9seauFullyConnected/01_MonPremierR%C3%A9seau.html" />
    <link rel="prev" title="Derivative and Gradient Descent" href="01_D%C3%A9riv%C3%A9esEtDescenteDuGradient.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>
<aside class="bd-header-announcement" aria-label="Announcement">
  <div class="bd-header-announcement__content"><span style="font-size:2em; font-weight:bold;">ğŸš€ Learn Deep Learning from scratch ğŸš€</span></div>
</aside>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning Course</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Deep Learning Course ğŸš€
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ§® Foundations</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_D%C3%A9riv%C3%A9esEtDescenteDuGradient.html">Derivative and Gradient Descent</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ”— Fully Connected Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../02_R%C3%A9seauFullyConnected/01_MonPremierR%C3%A9seau.html">My First Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_R%C3%A9seauFullyConnected/02_PytorchIntroduction.html">Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_R%C3%A9seauFullyConnected/03_TechniquesAvanc%C3%A9es.html">Advanced Techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ–¼ï¸ Convolutional Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../03_R%C3%A9seauConvolutifs/01_CouchesDeConvolutions.html">Convolutional Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_R%C3%A9seauConvolutifs/02_R%C3%A9seauConvolutif.html">Convolutional Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_R%C3%A9seauConvolutifs/03_ConvImplementation.html">Implementing the Convolution Layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_R%C3%A9seauConvolutifs/04_R%C3%A9seauConvolutifPytorch.html">Convolutional Networks with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_R%C3%A9seauConvolutifs/05_ApplicationClassification.html">Application on a color image dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_R%C3%A9seauConvolutifs/06_ApplicationSegmentation.html">Applying Segmentation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ”„ Autoencoders</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../04_Autoencodeurs/01_IntuitionEtPremierAE.html">Introduction to Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_Autoencodeurs/02_DenoisingAE.html">Autoencoder for Denoising</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ“ NLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../05_NLP/01_Introduction.html">Introduction to NLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_NLP/02_bigramme.html">Bigram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_NLP/03_R%C3%A9seauFullyConnected.html">Fully Connected Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_NLP/04_WaveNet.html">PyTorch and WaveNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_NLP/05_Rnn.html">Recurrent Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_NLP/06_Lstm.html">Long Short-Term Memory</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ¤— HuggingFace</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../06_HuggingFace/01_introduction.html">Introduction to Hugging Face</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_HuggingFace/02_ComputerVisionWithTransformers.html">Computer Vision with Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_HuggingFace/03_NlpWithTransformers.html">Natural Language Processing with Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_HuggingFace/04_AudioWithTransformers.html">Audio Processing with Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_HuggingFace/05_ImageGenerationWithDiffusers.html">Image Generation with Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_HuggingFace/06_DemoAvecGradio.html">Demo with Gradio</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">âš¡ Transformers</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../07_Transformers/01_Introduction.html">Introduction to Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_Transformers/02_GptFromScratch.html">Building a GPT from Scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_Transformers/03_TrainingOurGpt.html">Training our GPT model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_Transformers/04_ArchitectureEtParticularit%C3%A9s.html">Transformer architecture and features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_Transformers/05_UtilisationsPossibles.html">Possible Applications of the Transformer Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_Transformers/06_VisionTransformerImplementation.html">Implementing the Vision Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_Transformers/07_SwinTransformer.html">Swin Transformer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ¯  Object Detection (YOLO)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../08_DetectionEtYolo/01_Introduction.html">Introduction to Object Detection in Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08_DetectionEtYolo/02_YoloEnDetail.html">YOLO in Detail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08_DetectionEtYolo/03_Ultralytics.html">Ultralytics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ” Contrastive Training</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../09_EntrainementContrastif/01_FaceVerification.html">Facial Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09_EntrainementContrastif/02_NonSupervis%C3%A9.html">Unsupervised Contrastive Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ“ Transfer Learning and Distillation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../10_TransferLearningEtDistillation/01_TransferLearning.html">Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_TransferLearningEtDistillation/02_TransferLearningPytorch.html">Transfer Learning with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_TransferLearningEtDistillation/03_Distillation.html">Knowledge Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_TransferLearningEtDistillation/04_DistillationAnomalie.html">Knowledge Distillation for Unsupervised Anomaly Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_TransferLearningEtDistillation/05_FineTuningLLM.html">Fine-Tuning of LLMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_TransferLearningEtDistillation/06_FineTuningBertHF.html">Fine-tuning BERT with Hugging Face</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ¨ Generative Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/01_Introduction.html">Introduction to Generative Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/02_GAN.html">Generative Adversarial Networks (GANs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/03_GanImplementation.html">Implementing a GAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/04_VAE.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/05_VaeImplementation.html">Implementing a VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/06_NormalizingFlows.html">Normalizing Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/07_DiffusionModels.html">Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ModelesGeneratifs/08_DiffusionImplementation.html">Implementing a Diffusion Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ğŸ Bonus â€“ Specific Topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/01_ActivationEtInitialisation.html">Activations and Initializations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/02_BatchNorm.html">Batch Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/03_DataAugmentation.html">Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/04_Broadcasting.html">Broadcasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/05_Optimizer.html">Understanding Different Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/06_Regularisation.html">Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/07_ConnexionsResiduelles.html">Residual Connections</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/08_CrossValidation.html">Introduction to Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/09_MetriquesEvaluation.html">Model Evaluation Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/10_Tokenization.html">Introduction to Tokenization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bonus_CoursSp%C3%A9cifiques/11_Quantization.html">Quantization</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/SimonThomine/CoursDeepLearning" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/SimonThomine/CoursDeepLearning/edit/main/en/01_Fondations/02_RÃ©gressionLogistique.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/SimonThomine/CoursDeepLearning/issues/new?title=Issue%20on%20page%20%2F01_Fondations/02_RÃ©gressionLogistique.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/01_Fondations/02_RÃ©gressionLogistique.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Logistic Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-artificial-neuron">The Artificial Neuron</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application">Application</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-function">Cost Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-derivatives">Calculating Derivatives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Logistic Regression</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="logistic-regression">
<h1>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h1>
<section id="the-artificial-neuron">
<h2>The Artificial Neuron<a class="headerlink" href="#the-artificial-neuron" title="Link to this heading">#</a></h2>
<p>Letâ€™s dive into the heart of the matter: the artificial neuron!</p>
<p>The figure below shows how an artificial neuron works:</p>
<p><img alt="Artificial Neuron" src="../_images/NeuroneArtificiel.png" /></p>
<p>An artificial neuron takes a vector <span class="math notranslate nohighlight">\(\mathbf{x}=(x_1,x_2,...,x_n)\)</span> as input. Each element <span class="math notranslate nohighlight">\(x_i\)</span> of the vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is multiplied by a weight <span class="math notranslate nohighlight">\(w_i\)</span>, then the sum is calculated and a bias <span class="math notranslate nohighlight">\(b\)</span> is added. This sum is then passed through a function called the <strong>activation function</strong> <span class="math notranslate nohighlight">\(\phi\)</span>.
<span class="math notranslate nohighlight">\(Output = \phi(\sum_{i=0}^{n} w_i x_i  + b)\)</span>
This process is called an artificial neuron because it is inspired by the functioning of a <a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_neuron">biological neuron</a>.</p>
</section>
<section id="activation-functions">
<h2>Activation Functions<a class="headerlink" href="#activation-functions" title="Link to this heading">#</a></h2>
<p><strong>Heaviside Function:</strong> Originally, the first artificial neuron (<a class="reference external" href="https://fr.wikipedia.org/wiki/Perceptron">the perceptron</a>) used a threshold function as the activation function. This allows making a decision (0 or 1) based on the weighted sum and a defined threshold.
<span class="math notranslate nohighlight">\(heaviside(x) = \left\{
    \begin{array}{ll}
        1 &amp; \text{if } x &gt; 0 \\
        0 &amp; \text{otherwise}
    \end{array}
\right. \text{with } x=\sum_{i=0}^{n} w_i x_i  + b\)</span>
This activation function is effective for binary classification, but it does not work for multiple classes. Additionally, the function is not differentiable, which complicates the use of the gradient descent algorithm to optimize the neuronâ€™s weights <span class="math notranslate nohighlight">\(w_i\)</span>.</p>
<p>Recent activation functions are much more interesting for training neural networks using gradient descent. First, they are differentiable, allowing the application of our gradient descent algorithm. Second, they are nonlinear, enabling networks to learn complex representations. There are also other specific advantages to each activation function.</p>
<p>One of the â€œrecentâ€ activation functions is the sigmoid function, which we detail here:</p>
<p><strong>Sigmoid Function:</strong> Another particularly interesting activation function due to its analogy with probability is the sigmoid function. This time, the function allows obtaining a value between 0 and 1 using the formula:
<span class="math notranslate nohighlight">\(sigmoid(x) = \frac{1}{1 + e^{-x}} \text{ with } x=\sum_{i=0}^{n} w_i x_i  + b\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># TracÃ© de la fonction sigmoÃ¯de</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Fonction sigmoÃ¯de&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;sigmoid(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/cb2a6b5327d1de2209c0b7d14fce71c47416801bce8208628ada2d92dc021e7c.png" src="../_images/cb2a6b5327d1de2209c0b7d14fce71c47416801bce8208628ada2d92dc021e7c.png" />
</div>
</div>
<p>This function is differentiable, and its derivative is:
<span class="math notranslate nohighlight">\(sigmoid'(x) = sigmoid(x) \cdot (1 - f(x))\)</span>
Therefore, we can apply gradient descent to our artificial neuron when using this activation function.</p>
<p>There are many other <a class="reference external" href="https://fr.wikipedia.org/wiki/Fonction_d%27activation">activation functions</a> each with their own uses. We will see them in the following courses. (<span class="math notranslate nohighlight">\(Tanh\)</span>, <span class="math notranslate nohighlight">\(ReLU\)</span>, <span class="math notranslate nohighlight">\(Softmax\)</span>)</p>
</section>
<section id="application">
<h2>Application<a class="headerlink" href="#application" title="Link to this heading">#</a></h2>
<p>To fully understand logistic regression, nothing beats a concrete example.</p>
<p>In this example, we will determine whether a student will be admitted to their dream university based on three pieces of information: their entrance exam score, their average grades from the previous year, and the quality of their motivation letter.</p>
<p>We do not know the calculation method for admitting or rejecting a student, but we have the data and corresponding decisions.</p>
<p>The input information ranges from 0 to 1, with 1 indicating the best score. Admitted = 1 corresponds to admission, while Admitted = 0 corresponds to rejection.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tabulate</span><span class="w"> </span><span class="kn">import</span> <span class="n">tabulate</span>

<span class="c1"># DÃ©finition des donnÃ©es d&#39;entraÃ®nement</span>
<span class="n">values_train</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]]</span>
<span class="n">labels_train</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Ajout des noms de colonnes</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;Examen&#39;</span><span class="p">,</span> <span class="s1">&#39;Moyenne&#39;</span><span class="p">,</span> <span class="s1">&#39;Motivation&#39;</span><span class="p">,</span> <span class="s1">&#39;Admis&#39;</span><span class="p">]]</span>
<span class="n">data</span><span class="o">.</span><span class="n">extend</span><span class="p">([[</span><span class="n">values_train</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">values_train</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">values_train</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span> <span class="n">labels_train</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">values_train</span><span class="p">))])</span>

<span class="c1"># Affichage du tableau</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;firstrow&quot;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;fancy_grid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>â•’â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â••
â”‚   Examen â”‚   Moyenne â”‚   Motivation â”‚   Admis â”‚
â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡
â”‚      0.7 â”‚       0.8 â”‚          0.1 â”‚       1 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      0.4 â”‚       0.9 â”‚          0.5 â”‚       0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      0.2 â”‚       0.3 â”‚          0.9 â”‚       0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      0.9 â”‚       0.9 â”‚          0.6 â”‚       1 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•›
</pre></div>
</div>
</div>
</div>
<p>Our goal in this problem is to determine whether students with the scores <span class="math notranslate nohighlight">\([Exam=0.8, Average=0.7, Motivation=0.2]\)</span> and <span class="math notranslate nohighlight">\([Exam=0.4, Average=0.5, Motivation=0.9]\)</span> were admitted.</p>
<p>Youâ€™ve understood that the data <span class="math notranslate nohighlight">\(Exam\)</span>, <span class="math notranslate nohighlight">\(Average\)</span>, and <span class="math notranslate nohighlight">\(Motivation\)</span> correspond to our <span class="math notranslate nohighlight">\(x_i\)</span>. Our goal with logistic regression is to find an optimal value for the <span class="math notranslate nohighlight">\(w_i\)</span> that aligns with our training data.</p>
<p>For simplicity, letâ€™s define <span class="math notranslate nohighlight">\(x_0=Exam\)</span>, <span class="math notranslate nohighlight">\(x_1=Average\)</span>, <span class="math notranslate nohighlight">\(x_2=Motivation\)</span>, and <span class="math notranslate nohighlight">\(y_{true}=Admitted\)</span>.</p>
<section id="cost-function">
<h3>Cost Function<a class="headerlink" href="#cost-function" title="Link to this heading">#</a></h3>
<p>In our gradient descent example, our goal was to find the minimum of a function. These are the scenarios where gradient descent excels. For our new problem, we need to find a function that, when minimized, improves predictions.</p>
<p>In our binary classification, <span class="math notranslate nohighlight">\(y_{true}\)</span> is 1 if the student is admitted and 0 otherwise.</p>
<p>Our goal is to predict whether the student is admitted or not by predicting the output <span class="math notranslate nohighlight">\(pred\)</span>.</p>
<p>During training, we want to train our logistic regression model to predict <span class="math notranslate nohighlight">\(pred \approx y_{true}\)</span>.</p>
<p>To do this, we use the negative likelihood function, which is expressed as follows:
<span class="math notranslate nohighlight">\(\text{loss} = - \left( y_{\text{true}} \cdot \log(\text{pred}) + (1 - y_{\text{true}}) \cdot \log(1 - \text{pred}) \right)\)</span></p>
<p>For more details on logistic regression and negative likelihood loss, you can consult this <a class="reference external" href="https://blog.demir.io/understanding-logistic-regression-26802c0da856">link</a>.</p>
<p>The important thing is to understand how this function varies based on our prediction <span class="math notranslate nohighlight">\(pred\)</span> and the label <span class="math notranslate nohighlight">\(y_{true}\)</span>.</p>
<p>For this, letâ€™s consider the case where the label is <span class="math notranslate nohighlight">\(y_{true}=1\)</span>. Letâ€™s analyze two scenarios:</p>
<p>If <span class="math notranslate nohighlight">\(pred=0.9\)</span>, meaning our model predicts a 90% chance of admission (a good prediction), then:
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.9) + (1 - 1.0) \cdot \log(1 - 0.9) \right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.9) + 0 \cdot \log(1 - 0.9) \right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.9)\right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.9)\right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = 0.046\)</span>
The loss is low, which is good because the prediction is accurate.</p>
<p>If <span class="math notranslate nohighlight">\(pred=0.2\)</span>, meaning our model predicts a 20% chance of admission (a bad prediction), then:
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.2) + (1 - 1.0) \cdot \log(1 - 0.2) \right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.2) + 0 \cdot \log(1 - 0.2) \right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.2)\right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = - \left( 1.0 \cdot \log(0.2)\right)\)</span>
<span class="math notranslate nohighlight">\(\text{loss} = 0.70\)</span>
The loss is high, which is good because the prediction is poor.</p>
<p>For a case where <span class="math notranslate nohighlight">\(y_{true}=0\)</span>, we find a low loss when <span class="math notranslate nohighlight">\(pred\)</span> is close to 0 and a high loss when <span class="math notranslate nohighlight">\(pred\)</span> is close to 1 (you can do the calculation to practice if needed).</p>
</section>
<section id="calculating-derivatives">
<h3>Calculating Derivatives<a class="headerlink" href="#calculating-derivatives" title="Link to this heading">#</a></h3>
<p>Now that we have a function to minimize, it is necessary to calculate the derivative of this function with respect to each of the weights <span class="math notranslate nohighlight">\(w_0\)</span>, <span class="math notranslate nohighlight">\(w_1\)</span>, <span class="math notranslate nohighlight">\(w_2\)</span>, and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>We must therefore calculate <span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial w_0}\)</span>, <span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial w_1}\)</span>, <span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial w_2}\)</span>, and <span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial b}\)</span>.</p>
<p>For the weights <span class="math notranslate nohighlight">\(w_0\)</span>, <span class="math notranslate nohighlight">\(w_1\)</span>, and <span class="math notranslate nohighlight">\(w_2\)</span>, the derivative is calculated in the same way.</p>
<p>Using the chain rule, for <span class="math notranslate nohighlight">\(w_0\)</span>, we have:
<span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial w_0} = \frac{\partial loss}{\partial pred} \cdot \frac{\partial pred}{\partial w_0}\)</span></p>
<p>As a reminder, our prediction <span class="math notranslate nohighlight">\(pred\)</span> corresponds to the output of our logistic regression with the activation function <span class="math notranslate nohighlight">\(sigmoid\)</span>.</p>
<p>For the first term, the derivative of the loss with respect to <span class="math notranslate nohighlight">\(pred\)</span> gives:
<span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial pred} = -(\frac{y_{true}}{pred} - \frac{1-y_{true}}{1-pred}) \)</span>
The calculation will not be detailed here, but you can do it yourself to verify.</p>
<p>For the second term, the derivative of <span class="math notranslate nohighlight">\(pred\)</span> with respect to <span class="math notranslate nohighlight">\(w_0\)</span> gives:
<span class="math notranslate nohighlight">\(\frac{\partial pred}{\partial w_0} = pred \cdot (1-pred) \cdot x_0\)</span></p>
<p>Combining the two terms, we get:
<span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial w_0} =-(\frac{y_{true}}{pred} - \frac{1-y_{true}}{1-pred}) \cdot pred \cdot (1-pred) \cdot x_0\)</span></p>
<p>And after simplification (magically),
<span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial w_0} = (pred-y_{true}) \cdot x_0\)</span></p>
<p>Without detailing the calculation, we also get:
<span class="math notranslate nohighlight">\(\frac{\partial loss}{\partial b} = pred-y_{true}\)</span></p>
</section>
<section id="id1">
<h3>Logistic Regression<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Now that we have all the elements,
letâ€™s define our logistic regression function in Python:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Notre classe de regression logistique</span>
<span class="k">class</span><span class="w"> </span><span class="nc">logistic_regression</span><span class="p">():</span>
  <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">=</span><span class="mi">0</span>
  <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x0</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">):</span>
    <span class="c1"># Somme pondÃ©rÃ©e et ajout du biais</span>
    <span class="n">pond</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">w0</span><span class="o">*</span><span class="n">x0</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="o">*</span><span class="n">x1</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="o">*</span><span class="n">x2</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span>
    <span class="c1"># Application de la sigmoÃ¯de</span>
    <span class="n">pred</span><span class="o">=</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pond</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pred</span>
    
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="c1"># Calcul du loss (log vraisemblance nÃ©gative)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">loss</span>
    

<span class="k">def</span><span class="w"> </span><span class="nf">update_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">pred</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
       
  <span class="c1"># On calcule les dÃ©rivÃ©es en fonction des poids et du biais </span>
  <span class="n">dL_dw0</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">*</span> <span class="n">x0</span>
  <span class="n">dL_dw1</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">*</span> <span class="n">x1</span>
  <span class="n">dL_dw2</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">*</span> <span class="n">x2</span>
  <span class="n">dL_db</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">y_true</span>
      
  <span class="c1"># On modifie les paramÃ¨tres pour rÃ©duire le loss </span>
  <span class="c1"># La modification des poids dÃ©pend du learning rate, du signe de la dÃ©rivÃ©e et de la valeur de la dÃ©rivÃ©e</span>
  <span class="n">model</span><span class="o">.</span><span class="n">w0</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dL_dw0</span>
  <span class="n">model</span><span class="o">.</span><span class="n">w1</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dL_dw1</span>
  <span class="n">model</span><span class="o">.</span><span class="n">w2</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dL_dw2</span>
  <span class="n">model</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dL_db</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialisation du modÃ¨le et des hyperparamÃ¨tres</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1"># le nombre d&#39;itÃ©rations d&#39;entrainement</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">logistic_regression</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Before training the model, letâ€™s test our predictions on the two students whose admission results we want to know.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">values_test</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.7</span><span class="p">],[</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.9</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values_test</span><span class="p">:</span>
  <span class="n">x0</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="o">=</span><span class="n">value</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L&#39;Ã©lÃ¨ve avec Examen = &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot;, Moyenne = &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot; et Motivation = &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot; a &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pred</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">% d</span><span class="s2">e chance d&#39;Ãªtre admis&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L&#39;Ã©lÃ¨ve avec Examen = 0.8, Moyenne = 0.7 et Motivation = 0.7 a 60% de chance d&#39;Ãªtre admis
L&#39;Ã©lÃ¨ve avec Examen = 0.4, Moyenne = 0.5 et Motivation = 0.9 a 59% de chance d&#39;Ãªtre admis
</pre></div>
</div>
</div>
</div>
<p>We can see that the model is very uncertain and gives random probabilities, which is logical since its weights are initialized randomly.</p>
<p>Now, letâ€™s train the model on our training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># EntraÃ®nement</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
  <span class="c1"># Mise Ã  jour des poids pour chaque exemple</span>
  <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">),</span> <span class="n">y_true</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">values_train</span><span class="p">,</span> <span class="n">labels_train</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
    <span class="n">update_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">pred</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

  <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels_train</span><span class="p">)</span>
  
  <span class="c1"># Affichage de la perte pour suivre la progression de l&#39;entraÃ®nement</span>
  <span class="k">if</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">epoch</span><span class="o">==</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/40000, Loss: 0.01468091027998586
Epoch 5000/40000, Loss: 0.013032955086147595
Epoch 10000/40000, Loss: 0.011715352279809266
Epoch 15000/40000, Loss: 0.010638348324912276
Epoch 20000/40000, Loss: 0.009741762611763436
Epoch 25000/40000, Loss: 0.008983896958517028
Epoch 30000/40000, Loss: 0.008334957514714105
Epoch 35000/40000, Loss: 0.007773096000082178
Epoch 40000/40000, Loss: 0.007281930357182074
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">w0</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">w1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">w2</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

<span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values_test</span><span class="p">:</span>
  <span class="n">x0</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="o">=</span><span class="n">value</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L&#39;Ã©lÃ¨ve avec Examen = &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot;, Moyenne = &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot; et Motivation = &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span><span class="o">+</span> <span class="s2">&quot; a &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">pred</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">% d</span><span class="s2">e chance d&#39;Ãªtre admis&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>19.464301071981186 -3.27230109363944 -8.244865180820856 -4.903197398150705
L&#39;Ã©lÃ¨ve avec Examen = 0.8, Moyenne = 0.7 et Motivation = 0.7 a 93% de chance d&#39;Ãªtre admis
L&#39;Ã©lÃ¨ve avec Examen = 0.4, Moyenne = 0.5 et Motivation = 0.9 a 0% de chance d&#39;Ãªtre admis
</pre></div>
</div>
</div>
</div>
<p>As we can see, our model is now much more confident in its predictions and gives us predictions consistent with the training data.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./01_Fondations"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_D%C3%A9riv%C3%A9esEtDescenteDuGradient.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Derivative and Gradient Descent</p>
      </div>
    </a>
    <a class="right-next"
       href="../02_R%C3%A9seauFullyConnected/01_MonPremierR%C3%A9seau.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">My First Neural Network</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-artificial-neuron">The Artificial Neuron</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application">Application</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-function">Cost Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-derivatives">Calculating Derivatives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Logistic Regression</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Simon Thomine
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div id="language-switcher" style="text-align: center; margin-top: 20px; padding: 10px; border-top: 1px solid #eee;">
  <span style="margin-right: 10px;">ğŸŒ Language / Langue:</span>
  <a href="#" onclick="switchToEnglish()" style="text-decoration: none; margin: 0 5px; padding: 5px 10px; background: #4CAF50; color: white; border-radius: 5px; font-weight: bold; transition: all 0.3s;">ğŸ‡ºğŸ‡¸ English</a>
  <a href="#" onclick="switchToFrench()" style="text-decoration: none; margin: 0 5px; padding: 5px 10px; background: #f0f0f0; border-radius: 5px; transition: all 0.3s;">ğŸ‡«ğŸ‡· FranÃ§ais</a>
  <a href="#" onclick="switchToSpanish()" style="text-decoration: none; margin: 0 5px; padding: 5px 10px; background: #ffd700; border-radius: 5px; transition: all 0.3s;">ğŸ‡ªğŸ‡¸ EspaÃ±ol</a>
  <a href="#" onclick="switchToChinese()" style="text-decoration: none; margin: 0 5px; padding: 5px 10px; background: #ff4b4b; color: white; border-radius: 5px; transition: all 0.3s;">ğŸ‡¨ğŸ‡³ ä¸­æ–‡</a>
</div>
<script>
function getBaseUrl() {
  let baseUrl = window.location.origin;
  let pathname = window.location.pathname;
  if (pathname.includes('fr/')) {
    baseUrl += pathname.split('fr/')[0];
  } else if (pathname.includes('en/')) {
    baseUrl += pathname.split('en/')[0];
  } else if (pathname.includes('es/')) {
    baseUrl += pathname.split('es/')[0];
  } else if (pathname.includes('zh/')) {
    baseUrl += pathname.split('zh/')[0];
  } else {
    baseUrl += pathname.split('/').slice(0, -1).join('/') + '/';
  }
  return baseUrl;
}

function getCurrentPage() {
  let pathname = window.location.pathname;
  if (pathname.includes('fr/')) {
    return pathname.split('fr/')[1] || 'index.html';
  } else if (pathname.includes('en/')) {
    return pathname.split('en/')[1] || 'index.html';
  } else if (pathname.includes('es/')) {
    return pathname.split('es/')[1] || 'index.html';
  } else if (pathname.includes('zh/')) {
    return pathname.split('zh/')[1] || 'index.html';
  }
  return 'index.html';
}

function switchToEnglish() {
  const baseUrl = getBaseUrl();
  const currentPage = getCurrentPage();
  const newUrl = baseUrl + 'en/' + currentPage;
  window.location.href = newUrl;
}

function switchToFrench() {
  const baseUrl = getBaseUrl();
  const currentPage = getCurrentPage();
  const newUrl = baseUrl + 'fr/' + currentPage;
  window.location.href = newUrl;
}

function switchToSpanish() {
  const baseUrl = getBaseUrl();
  const currentPage = getCurrentPage();
  const newUrl = baseUrl + 'es/' + currentPage;
  window.location.href = newUrl;
}

function switchToChinese() {
  const baseUrl = getBaseUrl();
  const currentPage = getCurrentPage();
  const newUrl = baseUrl + 'zh/' + currentPage;
  window.location.href = newUrl;
}
</script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>