{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento del lenguaje natural con Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno, utilizamos la biblioteca **Transformers** de Hugging Face para el procesamiento del lenguaje natural (NLP). Los modelos de lenguaje más avanzados (como GPT, Llama, etc.) requieren mucha memoria y suelen ser inutilizables en una computadora portátil. Por ello, nos limitamos a modelos más pequeños, aunque menos potentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatBot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente, el uso más común de los modelos de lenguaje (LLM) es el **ChatBot**, un asistente virtual que responde a nuestras preguntas.\n",
    "Con Hugging Face, puedes crear tu propio ChatBot localmente de la siguiente manera.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos una versión simplificada de [BlenderBot](https://ai.meta.com/blog/blenderbot-3-a-175b-parameter-publicly-available-chatbot-that-improves-its-skills-and-safety-over-time/) de Meta (`facebook/blenderbot-400M-distill`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aquilae/anaconda3/envs/dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = pipeline(task=\"conversational\",model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ChatBot solo entiende inglés, por lo que debes formularle preguntas en ese idioma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 44c34bd3-ea1b-44b6-bd54-9127133cc941\n",
      "user: What is the best  french deep learning course?\n",
      "assistant:  I'm not sure, but I do know that French is one of the most widely spoken languages in the world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Conversation\n",
    "user_message = \"\"\"What is the best french deep learning course?\"\"\"\n",
    "conversation = Conversation(user_message)\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, el modelo no está bien entrenado y no sabe que el mejor curso de *Deep Learning* es este.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si deseas hacer otra pregunta, el siguiente comando te proporciona la respuesta en una sola línea de código.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: d258da22-78e4-4621-a0e1-90776454a595\n",
      "user: What is the most tasty fruit?\n",
      "assistant:  I would have to say watermelon. It is so juicy and juicy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation=Conversation(\"What is the most tasty fruit?\")\n",
    "print(chatbot(conversation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si deseas continuar la conversación, utiliza esta función.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: c3e1a64c-5b40-4808-8632-38d9df14ed9d\n",
      "user: What is the most tasty fruit?\n",
      "assistant:  I would have to say watermelon. It is so juicy and juicy.\n",
      "user: What else do you recommend?\n",
      "assistant:  I would say mangos are pretty good too. They are sweet and tangy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Il faut spécifier le rôle (user) et ajouter votre message dans la conversation déjà existante\n",
    "conversation.add_message({\"role\": \"user\",\"content\": \"\"\"What else do you recommend?\"\"\"})\n",
    "print(chatbot(conversation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sabes cómo utilizar un ChatBot con la biblioteca **Transformers** de Hugging Face.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traducción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veremos cómo implementar un traductor. Utilizamos el modelo [No Language Left Behind](https://ai.meta.com/research/no-language-left-behind/) de Meta (`facebook/nllb-200-distilled-600M`), que permite traducir desde cualquier idioma. Por limitaciones de memoria, empleamos una versión simplificada del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traducteur = pipeline(task=\"translation\",model=\"facebook/nllb-200-distilled-600M\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le texte en anglais :  The best course of deep learning is this one.\n",
      "Le texte en japonais :  深い学習の最高のコースはこれです\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Le meilleur cours de d'apprentissage profond est celui-ci.\"\"\"\n",
    "text_translated = traducteur(text,src_lang=\"fra_Latn\",tgt_lang=\"eng_Latn\")\n",
    "print(\"Le texte en anglais : \", text_translated[0][\"translation_text\"])\n",
    "text_translated = traducteur(text,src_lang=\"fra_Latn\",tgt_lang=\"jpn_Jpan\")\n",
    "print(\"Le texte en japonais : \",text_translated[0][\"translation_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La traducción es muy buena (al menos para el inglés; ¡no tengo experiencia con el japonés!).\n",
    "También puedes probar otras combinaciones de idiomas especificando el código adecuado, que encontrarás en esta [página](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra tarea útil en NLP es el resumen de texto. El modelo debe ser capaz de extraer la información más relevante de un texto. Para ello, utilizamos el modelo [BART](https://research.facebook.com/publications/bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension/) de Meta (`facebook/bart-large-cnn`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumeur=pipeline(task=\"summarization\",model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le résumé du texte :  Troyes is a commune and the capital of the department of Aube in the Grand Est region of north-central France. It is located on the Seine river about 140 km (87 mi) south-east of Paris. Troyes had a population of 61,996 inhabitants in 2018.\n"
     ]
    }
   ],
   "source": [
    "text= \"Troyes is a beautiful city. Troyes is a commune and the capital of the department of Aube in the Grand Est region of north-central France. It is located on the Seine river about 140 km (87 mi) south-east of Paris. Troyes is situated within the Champagne wine region and is near to the Orient Forest Regional Natural Park.Troyes had a population of 61,996 inhabitants in 2018. It is the center of the Communauté d'agglomération Troyes Champagne Métropole, which was home to 170,145 inhabitants.\"\n",
    "summary = resumeur(text,min_length=10,max_length=100)\n",
    "print(\"Le résumé du texte : \",summary[0][\"summary_text\"]) #[\"summary_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resumen no es perfecto, ya que se trata de un modelo pequeño, pero ha logrado extraer la información clave y eliminar los elementos menos relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Embeddings* de frases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un aspecto importante del NLP que vimos en el curso es el *embedding*. Recordemos: esto consiste en proyectar nuestros *tokens* (palabras o caracteres, por ejemplo) en un espacio latente. Esto permite acercar palabras similares. Por ejemplo, palabras como *\"perros\"* y *\"gatos\"* estarán cerca en el espacio latente, mientras que *\"perro\"* y *\"es\"* estarán distantes.\n",
    "Podemos utilizar estos *embeddings* para calcular la similitud entre dos frases. Para ello, empleamos la biblioteca `sentence_transformers`, que permite extraer el *embedding* a partir de un modelo preentrenado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el modelo [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar la similitud entre diferentes frases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat is chasing the mouse \t\t The dog sleep in the kitchen \t\t Score: 0.0601\n",
      "A man is watching the television \t\t A boy watches TV \t\t Score: 0.7207\n",
      "The latest movie is awesome \t\t The new movie is so great \t\t Score: 0.7786\n"
     ]
    }
   ],
   "source": [
    "sentences1 = ['The cat is chasing the mouse','A man is watching the television','The latest movie is awesome']\n",
    "sentences2 = ['The dog sleeps in the kitchen','A boy watches TV','The new movie is so great']\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2,convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1,embeddings2)\n",
    "for i in range(len(sentences1)):\n",
    "  print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i],\n",
    "                                                sentences2[i],\n",
    "                                                cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, las frases con significados similares tienen *embeddings* bastante parecidos. Por lo tanto, este modelo es útil para extraer *embeddings*.\n",
    "Contar con un buen modelo para extraer *embeddings* suele ser un primer paso en un proyecto de NLP.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
