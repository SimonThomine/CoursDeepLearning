{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas avanzadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este curso, exploraremos técnicas para mejorar la confiabilidad y facilidad de entrenamiento de las redes neuronales.\n",
    "Para ilustrar estas técnicas, utilizaremos el conjunto de datos [MNIST](https://es.wikipedia.org/wiki/Base_de_datos_MNIST), que contiene imágenes de dígitos manuscritos del 0 al 9.\n",
    "El objetivo es que la red tome una imagen como entrada y determine qué dígito representa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del conjunto de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, descargamos el conjunto de datos MNIST. La biblioteca *torchvision* permite gestionar imágenes con PyTorch y proporciona herramientas para cargar conjuntos de datos comunes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=T.ToTensor() # Pour convertir les éléments en tensor torch directement\n",
    "dataset = datasets.MNIST(root='./../data', train=True, download=True,transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./../data', train=False,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le chiffre sur l'image est un 5\n"
     ]
    }
   ],
   "source": [
    "# On peut visualiser les éléments du dataset\n",
    "plt.imshow(dataset[0][0].permute(1,2,0).numpy(), cmap='gray')\n",
    "plt.show()\n",
    "print(\"Le chiffre sur l'image est un \"+str(dataset[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División en entrenamiento/validación/prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habrás observado, al cargar el conjunto de datos, contamos con un *train_dataset* y un *test_dataset*. Esta es una práctica esencial para entrenar una red neuronal.\n",
    "De hecho, una red entrenada con ciertos datos suele tener un buen rendimiento con esos mismos datos. Por lo tanto, es necesario crear un *dataset de prueba* para evaluar el modelo con datos no vistos durante el entrenamiento.\n",
    "\n",
    "En la práctica, se utilizan 3 subconjuntos:\n",
    "- El *training split* para entrenar el modelo.\n",
    "- El *validation split* para evaluar el modelo durante el entrenamiento.\n",
    "- El *test split* para evaluar el modelo al final del entrenamiento (este es el resultado más importante).\n",
    "\n",
    "Una práctica común es utilizar una división 60-20-20, es decir, 60% de los datos para entrenamiento, 20% para validación y 20% para prueba. Sin embargo, esta recomendación no es adecuada para todos los conjuntos de datos. Si el conjunto de datos contiene muchas imágenes, se puede reducir la proporción de datos de validación y prueba. Por ejemplo, para conjuntos de datos con miles de millones de imágenes, se suelen utilizar divisiones como 98-1-1 o incluso 99.8-0.1-0.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le train et test sont déjà séparé, on va donc séparer le train_dataset en train et validation\n",
    "train_dataset, validation_dataset=torch.utils.data.random_split(dataset, [0.8,0.2])\n",
    "\n",
    "# Création des dataloaders pour séparer en mini-batch automatiquement\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader= DataLoader(validation_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación y entrenamiento de un primer modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el cuaderno anterior, creamos un modelo completamente conectado para el entrenamiento. Dado que los datos de entrada son imágenes de tamaño $28 \\times 28$, es necesario convertirlas en un vector 1D de tamaño $28 \\times 28 = 784$ para procesarlas en la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) # première couche cachée \n",
    "    self.fc2=nn.Linear(256,256) # seconde couche cachée \n",
    "    self.fc3=nn.Linear(256,10) # couche de sortie\n",
    "    \n",
    "  # La fonction forward est la fonction appelée lorsqu'on fait model(x)\n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28) # Pour convertir l'image de taille 28x28 en tensor de taille 784\n",
    "    x=F.relu(self.fc1(x)) # le F.relu permet d'appliquer la fonction d'activation ReLU sur la sortie de notre couche \n",
    "    x=F.relu(self.fc2(x))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Nombre de paramètres 269322\n"
     ]
    }
   ],
   "source": [
    "model = mlp()\n",
    "print(model)\n",
    "print(\"Nombre de paramètres\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de pérdida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la función de pérdida, utilizamos la *cross entropy loss* de PyTorch, que corresponde a la función de pérdida de la regresión logística para un número de clases mayor que 2.\n",
    "La función de pérdida se expresa de la siguiente manera:\n",
    "$\\text{Cross Entropy Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{ic} \\log(p_{ic})$\n",
    "donde:\n",
    "- $N$ es el número de ejemplos en el *mini-batch*.\n",
    "- $C$ es el número de clases.\n",
    "- $y_{ic}$ es el valor objetivo ($1$ si el ejemplo pertenece a la clase $c$ y $0$ en caso contrario).\n",
    "- $p_{ic}$ es la predicción de la probabilidad de pertenecer a la clase $c$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En pytorch\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros y entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo (puede tardar unos minutos, dependiendo de la potencia de tu computadora).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.29076647758483887\n",
      "step 0 val loss 0.15385286509990692\n",
      "step 1 train loss 0.10695428401231766\n",
      "step 1 val loss 0.10097559541463852\n",
      "step 2 train loss 0.07086848467588425\n",
      "step 2 val loss 0.09286081790924072\n",
      "step 3 train loss 0.05028771981596947\n",
      "step 3 val loss 0.08867377787828445\n",
      "step 4 train loss 0.04254501312971115\n",
      "step 4 val loss 0.0835222601890564\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación del modelo con los datos de prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que el modelo está entrenado, podemos verificar su rendimiento en el *test split*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.69\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo obtiene una precisión muy buena en la fase de prueba, lo cual es una buena señal.\n",
    "Sin embargo, observamos que durante el entrenamiento, la *pérdida de entrenamiento* es menor que la *pérdida de validación*. Este es un punto importante a considerar, ya que indica que el modelo presenta un ligero *overfitting*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting y underfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un elemento clave del aprendizaje profundo es la capacidad del modelo para no presentar *overfitting* con los datos de entrenamiento. El *overfitting* ocurre cuando un modelo aprende demasiado bien los datos de entrenamiento, pero no es capaz de generalizar a nuevos elementos de la misma distribución.\n",
    "Para comprender el principio, aquí hay una figura que muestra la diferencia entre el *underfitting* (modelo demasiado simple que no puede aprender la complejidad de los datos), un modelo bien entrenado y el *overfitting*.\n",
    "\n",
    "![Overfitting](./images/overfitting.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso más crítico de *overfitting*, el modelo tiene una precisión casi perfecta en los datos de entrenamiento, pero un mal rendimiento en los datos de validación y prueba.\n",
    "En este curso, introduciremos 2 métodos para evitar este problema de *overfitting*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización L2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regularización L2 es un método que consiste en añadir una penalización a la pérdida basada en el valor de los pesos del modelo. Esta penalización es proporcional al cuadrado de los valores de los pesos del modelo (cabe señalar que también existe la regularización L1, que es linealmente proporcional a los valores de los pesos del modelo). Esta penalización fomenta que los pesos del modelo permanezcan pequeños y sean menos sensibles al ruido de los datos de entrenamiento.\n",
    "Podemos formular la regularización L2 de la siguiente manera:\n",
    "$L(w) = L_0(w) + \\lambda \\sum_{i=1}^{n} w_i^2$\n",
    "donde:\n",
    "- $L(w)$ es la pérdida regularizada.\n",
    "- $L_0(w)$ es la función de pérdida clásica.\n",
    "- $\\lambda$ es el coeficiente de regularización.\n",
    "- $w_i$ es un peso del modelo.\n",
    "\n",
    "Para aprender más sobre la regularización L2, puedes consultar el [curso adicional sobre regularización](../Bonus_CoursSpécifiques/06_Regularisation.ipynb) o este [artículo](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos a entrenar añadiendo la regularización. En PyTorch, la regularización se utiliza añadiendo el parámetro *weight_decay* a nuestro *optimizer*. El valor de *weight_decay* corresponde al $\\lambda$ de la ecuación anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.2986273467540741\n",
      "step 0 val loss 0.1439662128686905\n",
      "step 1 train loss 0.11165566742420197\n",
      "step 1 val loss 0.10781095176935196\n",
      "step 2 train loss 0.07492929697036743\n",
      "step 2 val loss 0.09555892646312714\n",
      "step 3 train loss 0.05378309637308121\n",
      "step 3 val loss 0.08672302216291428\n",
      "step 4 train loss 0.041800014674663544\n",
      "step 4 val loss 0.0883878618478775\n"
     ]
    }
   ],
   "source": [
    "model_with_reg=mlp()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_reg.parameters(),lr=learning_rate,weight_decay=1e-5)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_reg(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_reg(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.73\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_reg(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia no es muy notable, pero observamos una disminución en la diferencia entre la pérdida de validación y la pérdida de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuición**: La regularización L2 funciona porque, al penalizar los coeficientes grandes, favorece soluciones en las que los pesos están distribuidos de manera más uniforme. Esto reduce la sensibilidad del modelo a las variaciones específicas de los datos de entrenamiento y mejora así la robustez y la generalización del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra técnica de regularización es el *dropout*. Este método consiste en desactivar aleatoriamente un porcentaje de neuronas en la red en cada paso del entrenamiento (los pesos desactivados cambian durante el entrenamiento). Cada neurona de una capa tiene una probabilidad $p$ de ser desactivada.\n",
    "\n",
    "Esta técnica obliga a la red a no depender de ciertas neuronas, sino a aprender representaciones más robustas y que generalicen mejor. Podemos ver el *dropout* como una especie de conjunto de modelos donde cada modelo es diferente (porque algunas neuronas están desactivadas). Durante la fase de prueba, se toma el \"promedio\" de estos diferentes modelos. Durante la fase de prueba, el *dropout* está desactivado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar el *dropout*, es necesario añadirlo directamente en la arquitectura de la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_dropout(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) \n",
    "    self.dropout1 = nn.Dropout(0.2) # on désactive 20% des neurones aléatoirement\n",
    "    self.fc2=nn.Linear(256,256) \n",
    "    self.dropout2 = nn.Dropout(0.2) # on désactive 20% des neurones aléatoirement\n",
    "    self.fc3=nn.Linear(256,10) \n",
    "  \n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28)\n",
    "    x=F.relu(self.dropout1(self.fc1(x)))\n",
    "    x=F.relu(self.dropout2(self.fc2(x)))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.3267715573310852\n",
      "step 0 val loss 0.19353896379470825\n",
      "step 1 train loss 0.13504144549369812\n",
      "step 1 val loss 0.14174170792102814\n",
      "step 2 train loss 0.10012412816286087\n",
      "step 2 val loss 0.13484247028827667\n",
      "step 3 train loss 0.07837768644094467\n",
      "step 3 val loss 0.10895466059446335\n",
      "step 4 train loss 0.0631122887134552\n",
      "step 4 val loss 0.10599609464406967\n"
     ]
    }
   ],
   "source": [
    "model_with_dropout=mlp_dropout()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_dropout.parameters(),lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_dropout(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_dropout(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  96.96\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_dropout(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos nuevamente una ligera mejora en el resultado del entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuición**: El *dropout* mejora la generalización al desactivar aleatoriamente neuronas durante el entrenamiento. Esto evita que el modelo dependa demasiado de ciertas neuronas y fomenta una distribución más robusta y diversificada de las características aprendidas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización por lotes (*Batch Normalization*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra técnica para mejorar el entrenamiento de una red neuronal es la *Normalización por lotes* (*Batch Normalization* o *BatchNorm*). El principio consiste en normalizar las entradas de cada capa de la red con una distribución que tenga una media nula y una varianza de 1.\n",
    "La normalización se realiza en el *batch* completo de la siguiente manera:\n",
    "\n",
    "Para un *mini-batch* $B$ con activaciones $x$:\n",
    "- $\\mu_B = \\frac{1}{m} \\sum_{i=1}^m x_i$: la media de las activaciones $x_i$ de los $m$ elementos.\n",
    "- $\\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i - \\mu_B)^2$: la varianza de las activaciones $x_i$ de los $m$ elementos.\n",
    "- $\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$: el valor normalizado de $x_i$.\n",
    "- $y_i = \\gamma \\hat{x}_i + \\beta$: la adición de los parámetros $\\gamma$ y $\\beta$ permite a la red aprender las distribuciones de activación óptimas.\n",
    "\n",
    "donde:\n",
    "- $m$ es el tamaño del *mini-batch* $B$.\n",
    "- $\\epsilon$ es una pequeña constante añadida para evitar la división por cero.\n",
    "- $\\gamma$ y $\\beta$ son parámetros aprendibles.\n",
    "\n",
    "En la práctica, se constatan 4 ventajas principales al utilizar *BatchNorm*:\n",
    "- **Aceleración del entrenamiento**: La normalización de las entradas de cada capa permite utilizar una *tasa de aprendizaje* más alta y, por lo tanto, acelerar la convergencia del entrenamiento.\n",
    "- **Reducción de la sensibilidad a la inicialización de los pesos**: La *BatchNorm* permite estabilizar la distribución de las activaciones, lo que hace que la red sea menos sensible a la inicialización de los pesos.\n",
    "- **Mejora de la generalización**: Al igual que el *dropout* y la regularización L2, la *BatchNorm* actúa como una forma de regularización. Esto se debe al ruido inducido al normalizar en el *batch*.\n",
    "- **Reducción del \"Internal Covariate Shift\"**: La estabilización de las activaciones a lo largo de la red permite reducir el cambio en las distribuciones de las capas internas, lo que facilita el aprendizaje.\n",
    "\n",
    "Lo que hay que recordar es que la *BatchNorm* ofrece numerosas ventajas y, por lo tanto, se recomienda utilizarla sistemáticamente.\n",
    "\n",
    "También existen otras técnicas de normalización como *LayerNorm*, *InstanceNorm*, *GroupNorm*, entre otras.\n",
    "Para aprender más sobre la *normalización por lotes*, puedes realizar el [curso adicional sobre *batch norm*](../Bonus_CoursSpécifiques/02_BatchNorm.ipynb), leer el [artículo](https://arxiv.org/pdf/1502.03167) o este [blogpost](https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739).\n",
    "Para obtener más información sobre la importancia de la normalización en el entrenamiento de redes neuronales, puedes consultar este [blogpost](https://medium.com/nerd-for-tech/overview-of-normalization-techniques-in-deep-learning-e12a79060daf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pratique, on constate 4 principaux avantages lors de l'utilisation de la *BatchNorm* :\n",
    "- **Accélération de l'entraînement** : La normalisation des entrées de chaque couche permet d'utiliser un *learning rate* plus élevé et donc d'accélérer la convergence de l'entraînement.\n",
    "- **Réduction de la sensibilité à l'initialisation des poids** : La *BatchNorm* permet de stabiliser la distribution des activations, ce qui rend le réseau moins sensible à l'initialisation des poids.\n",
    "- **Amélioration de la généralisation** : Comme le *dropout* et la régularisation L2, la *BatchNorm* agit comme une forme de régularisation. Cela est dû au bruit induit par le fait de normaliser sur le *batch*.\n",
    "- **Réduction du \"Internal Covariate Shift\"** : La stabilisation des activations tout au long du réseau permet de réduire le changement des distributions des couches internes, ce qui facilite l'apprentissage.\n",
    "\n",
    "Ce qu'il faut retenir, c'est que la *BatchNorm* offre de nombreux avantages et il est donc conseillé de l'utiliser systématiquement.\n",
    "\n",
    "Il existe également d'autres techniques de normalisation comme la *LayerNorm*, la *InstanceNorm*, la *GroupNorm* et d'autres ...\n",
    "Pour en apprendre plus sur la *batch normalization*, tu peux faire le [cours bonus sur la *batch norm*](../Bonus_CoursSpécifiques/02_BatchNorm.ipynb), lire le [papier](https://arxiv.org/pdf/1502.03167) ou le [blogpost](https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739).\n",
    "Pour avoir des informations supplémentaires sur l'intérêt de la normalisation pour l'entraînement des réseaux de neurones, tu peux consulter le [blogpost](https://medium.com/nerd-for-tech/overview-of-normalization-techniques-in-deep-learning-e12a79060daf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar la *BatchNorm* en PyTorch, es necesario añadirla directamente en la construcción del modelo. Cabe señalar que a menudo se aplica la *BatchNorm* antes de la función de activación, aunque ambas opciones son posibles (antes o después).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_bn(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.fc1=nn.Linear(784,256) \n",
    "    self.bn1=nn.BatchNorm1d(256) # Batch Normalization\n",
    "    self.fc2=nn.Linear(256,256) \n",
    "    self.bn2=nn.BatchNorm1d(256) # Batch Normalization\n",
    "    self.fc3=nn.Linear(256,10) \n",
    "  \n",
    "  def forward(self,x):\n",
    "    x=x.view(-1,28*28)\n",
    "    x=F.relu(self.bn1(self.fc1(x)))\n",
    "    x=F.relu(self.bn1(self.fc2(x)))\n",
    "    output=self.fc3(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 train loss 0.20796926319599152\n",
      "step 0 val loss 0.1327729970216751\n",
      "step 1 train loss 0.09048832952976227\n",
      "step 1 val loss 0.10177803039550781\n",
      "step 2 train loss 0.0635765939950943\n",
      "step 2 val loss 0.09861738979816437\n",
      "step 3 train loss 0.045849185436964035\n",
      "step 3 val loss 0.09643400460481644\n",
      "step 4 train loss 0.0397462323307991\n",
      "step 4 val loss 0.08524414896965027\n"
     ]
    }
   ],
   "source": [
    "model_with_bn=mlp_bn()\n",
    "epochs=5\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model_with_bn.parameters(),lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "  loss_train=0\n",
    "  for images, labels in train_loader:\n",
    "    preds=model_with_bn(images)\n",
    "    loss=criterion(preds,labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_train+=loss   \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} train loss {loss_train/len(train_loader)}\")\n",
    "  loss_val=0    \n",
    "  for images, labels in val_loader:\n",
    "    with torch.no_grad(): # permet de ne pas calculer les gradients\n",
    "      preds=model_with_bn(images)\n",
    "      loss=criterion(preds,labels)\n",
    "      loss_val+=loss \n",
    "  if i % 1 == 0:\n",
    "    print(f\"step {i} val loss {loss_val/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle en phase de test :  97.19\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader: \n",
    "  with torch.no_grad():\n",
    "    preds=model_with_bn(images)\n",
    "    \n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()     \n",
    "test_acc = 100 * correct / total\n",
    "print(\"Précision du modèle en phase de test : \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, la *BatchNorm* permite obtener una mejor puntuación en nuestros datos bajo las mismas condiciones de entrenamiento.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
