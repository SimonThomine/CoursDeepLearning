{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales recurrentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este curso, exploraremos las **redes neuronales recurrentes (RNN)** para predecir el siguiente carácter. Nos basamos en la arquitectura descrita en el artículo [*Recurrent neural network based language model*](https://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf), que propone una versión simplificada de RNN para esta tarea.\n",
    "\n",
    "**Ventaja clave**: a diferencia de los modelos basados en redes *fully connected* (vistos anteriormente), los RNN **no requieren un tamaño de contexto fijo**.\n",
    "\n",
    "Los RNN **mantenienen en memoria el contexto**, independientemente de la longitud de la secuencia. Aunque esto suena prometedor en teoría, veremos al final del curso que tienen limitaciones prácticas.\n",
    "\n",
    "![RNN](./images/rnn.png)\n",
    "\n",
    "*Figura extraída del artículo original.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona una RNN?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las RNN procesan los datos **de forma secuencial**: los caracteres se analizan uno a uno. El carácter siguiente depende tanto del **elemento actual** como del **estado oculto** ($s$), que almacena información de los caracteres anteriores.\n",
    "\n",
    "**Componentes matemáticos** (en un instante $t$):\n",
    "- **Entrada** ($x$): combinación del *one-hot encoding* del carácter actual ($w(t)$) y el estado previo ($s(t-1)$).\n",
    "  $x(t) = w(t) + s(t-1)$\n",
    "- **Estado oculto** ($s$): se actualiza aplicando la función *sigmoide* a la entrada.\n",
    "  $s(t) = sigmoid(x(t))$\n",
    "- **Salida** ($y$): probabilidades de los caracteres siguientes, calculadas con *softmax*.\n",
    "  $y(t) = softmax(s(t))$\n",
    "\n",
    "**Parámetro clave**: el **tamaño de la capa oculta** ($s$).\n",
    "**Inicialización**: $s(0)$ suele ser un vector pequeño (ej. ceros o valores aleatorios).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación práctica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El conjunto de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar **nombres de pila** con una RNN no es muy útil, ya que son cortos y el contexto es limitado. Para tareas más interesantes, necesitamos un conjunto de datos con un **contexto más amplio**.\n",
    "\n",
    "Usaremos un archivo de texto con los **diálogos de Molière**, creado a partir de sus obras completas disponibles en [Gutenberg.org](https://www.gutenberg.org/). Los datos se limpiaron para conservar **solo los diálogos**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de caractères dans le dataset :  1687290\n"
     ]
    }
   ],
   "source": [
    "with open('moliere.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(\"Nombre de caractères dans le dataset : \", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el conjunto de datos es grande, utilizaremos solo una parte (por ejemplo, los **primeros 50,000 caracteres**) para agilizar el procesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de caractères dans le dataset :  50000\n"
     ]
    }
   ],
   "source": [
    "text=text[:50000]\n",
    "print(\"Nombre de caractères dans le dataset : \", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeros **250 caracteres** del conjunto de datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALÈRE.\n",
      "\n",
      "Eh bien, Sabine, quel conseil me donnes-tu?\n",
      "\n",
      "SABINE.\n",
      "\n",
      "Vraiment, il y a bien des nouvelles. Mon oncle veut résolûment que ma\n",
      "cousine épouse Villebrequin, et les affaires sont tellement avancées,\n",
      "que je crois qu'ils eussent été mariés dès aujo\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de **caracteres únicos** en el dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !'(),-.:;?ABCDEFGHIJLMNOPQRSTUVYabcdefghijlmnopqrstuvxyzÇÈÉàâæçèéêîïôùû\n",
      "Nombre de caractères différents :  73\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(\"Nombre de caractères différents : \", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un **mapeo bidireccional** entre caracteres y enteros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encode : prend un string et output une liste d'entiers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decode: prend une liste d'entiers et output un string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos el dataset:\n",
    "1. Convertimos las cadenas de caracteres a enteros.\n",
    "2. Transformamos los enteros en **tensores de PyTorch**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32, 12, 22, 59, 28, 16,  8,  0,  0, 16, 41,  1, 35, 42, 38, 46,  6,  1,\n",
      "        29, 34, 35, 42, 46, 38,  6,  1, 49, 53, 38, 44,  1, 36, 47, 46, 51, 38,\n",
      "        42, 44,  1, 45, 38,  1, 37, 47, 46, 46, 38, 51,  7, 52, 53, 11,  0,  0,\n",
      "        29, 12, 13, 20, 24, 16,  8,  0,  0, 32, 50, 34, 42, 45, 38, 46, 52,  6,\n",
      "         1, 42, 44,  1, 56,  1, 34,  1, 35, 42, 38, 46,  1, 37, 38, 51,  1, 46,\n",
      "        47, 53, 54, 38, 44, 44, 38, 51,  8,  1, 23, 47, 46,  1, 47, 46, 36, 44,\n",
      "        38,  1, 54, 38, 53, 52,  1, 50, 66, 51, 47, 44, 72, 45, 38, 46, 52,  1,\n",
      "        49, 53, 38,  1, 45, 34,  0, 36, 47, 53, 51, 42, 46, 38,  1, 66, 48, 47,\n",
      "        53, 51, 38,  1, 32, 42, 44, 44, 38, 35, 50, 38, 49, 53, 42, 46,  6,  1,\n",
      "        38, 52,  1, 44, 38, 51,  1, 34, 39, 39, 34, 42, 50, 38, 51,  1, 51, 47,\n",
      "        46, 52,  1, 52, 38, 44, 44, 38, 45, 38, 46, 52,  1, 34, 54, 34, 46, 36,\n",
      "        66, 38, 51,  6,  0, 49, 53, 38,  1, 43, 38,  1, 36, 50, 47, 42, 51,  1,\n",
      "        49, 53,  3, 42, 44, 51,  1, 38, 53, 51, 51, 38, 46, 52,  1, 66, 52, 66,\n",
      "         1, 45, 34, 50, 42, 66, 51,  1, 37, 65, 51,  1, 34, 53, 43, 47])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:250]) # Les 250 premiers caractères encodé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en conjuntos de **entrenamiento** y **prueba**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # 90% pour le train et 10% pour le test\n",
    "train_data = data[:n]\n",
    "test = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: En cada iteración, recorremos **todo el dataset de forma secuencial**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Construyamos el modelo!\n",
    "\n",
    "Según el artículo, la **entrada** (carácter) se codifica en *one-hot* y se suma al **estado previo**. Necesitamos **dos capas fully connected**:\n",
    "1. **Primera capa**: transforma $x(t)$ en el estado oculto $s(t)$.\n",
    "2. **Segunda capa**: convierte $s(t)$ en la predicción $y(t)$.\n",
    "\n",
    "![RNN](./images/rnn_math.png)\n",
    "\n",
    "*Ecuación del artículo: $f$ = sigmoide, $g$ = softmax.*\n",
    "\n",
    "**Recomendación**: El [artículo original](https://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf) es claro y conciso. ¡Vale la pena leerlo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn(nn.Module): \n",
    "  def __init__(self,hidden_dim,vocab_size) -> None:\n",
    "    super(rnn, self).__init__()\n",
    "    self.hidden_to_hidden=nn.Linear(hidden_dim+vocab_size, hidden_dim)\n",
    "    self.hidden_to_output=nn.Linear(hidden_dim, vocab_size)\n",
    "    self.vocab_size=vocab_size\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.sigmoid=nn.Sigmoid() \n",
    "    \n",
    "  # Le réseau prend en entrée le caractère actuel et le state précédent\n",
    "  def forward(self, x,state):\n",
    "    # On one-hot encode le caractère\n",
    "    x = torch.nn.functional.one_hot(x, self.vocab_size).float()\n",
    "    if state is None:\n",
    "      # Si on a pas de state (début de la séquence), on initialise le state avec des petites valeurs aléatoires\n",
    "      state = torch.randn(self.hidden_dim) * 0.1\n",
    "    x = torch.cat((x, state), dim=-1)  # Concaténation de x et du state\n",
    "    state = self.sigmoid(self.hidden_to_hidden(x)) # Calcul du nouveau state\n",
    "    output = self.hidden_to_output(state) # Calcul de l'output\n",
    "    # On renvoie l'output et le state pour le prochain pas de temps\n",
    "    return output, state.detach() # detach() pour éviter de propager le gradient dans le state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parámetros de entrenamiento**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr=0.1\n",
    "hidden_dim=128\n",
    "model=rnn(hidden_dim,vocab_size)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Entrenemos el modelo!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Loss: 2.63949568\n",
      "Epoch: 1 \t Loss: 2.16456994\n",
      "Epoch: 2 \t Loss: 2.00850788\n",
      "Epoch: 3 \t Loss: 1.91673251\n",
      "Epoch: 4 \t Loss: 1.84440742\n",
      "Epoch: 5 \t Loss: 1.78986003\n",
      "Epoch: 6 \t Loss: 1.74923073\n",
      "Epoch: 7 \t Loss: 1.71709289\n",
      "Epoch: 8 \t Loss: 1.68791167\n",
      "Epoch: 9 \t Loss: 1.66215199\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    state=None\n",
    "    running_loss = 0\n",
    "    n=0\n",
    "    for i in range(len(train_data)-1):\n",
    "        x = train_data[i]\n",
    "        y = train_data[i+1]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred,state = model.forward(x,state)\n",
    "        loss = criterion(y_pred, y)\n",
    "        running_loss += loss.item()\n",
    "        n+=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: {0} \\t Loss: {1:.8f}\".format(epoch, running_loss/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con los **datos de prueba**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.77312289\n"
     ]
    }
   ],
   "source": [
    "state=None\n",
    "running_loss = 0\n",
    "n=0\n",
    "for i in range(len(train_data)-1):\n",
    "    with torch.no_grad():\n",
    "        x = train_data[i]\n",
    "        y = train_data[i+1]\n",
    "        y_pred,state = model.forward(x,state)\n",
    "        loss = criterion(y_pred, y)\n",
    "        running_loss += loss.item()\n",
    "        n+=1\n",
    "print(\"Loss: {0:.8f}\".format(running_loss/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **pérdida (*loss*)** en los datos de prueba es ligeramente mayor que en entrenamiento. El modelo presenta **ligero *overfitting***.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo entrenado, ¡podemos generar texto al **estilo de Molière**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "VARDILE.\n",
      "\n",
      "Vout on est nt, jes l'un ouint; sabhil.\n",
      "\n",
      "LE DOCTE.\n",
      "\n",
      "Si vous dicefalassîntes\n",
      "GIRGIB.\n",
      "\n",
      "MARGRIILÉ.\n",
      "\n",
      "LE DOCTE. Jort; et\n",
      "; bieu,\n",
      "et je mu tu d'ais d'ai coupce!\n",
      "\n",
      "SGÉLLÉ.\n",
      "\n",
      "Il Sgnous elli massit que\n",
      "Suis pluagil dés.\n",
      "Cais téscompas: y totte demes\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "moliere='.'\n",
    "sequence_length=250\n",
    "state=None\n",
    "for i in range(sequence_length):\n",
    "    x = torch.tensor(encode(moliere[-1]), dtype=torch.long).squeeze()\n",
    "    y_pred,state = model.forward(x,state)\n",
    "    probs=F.softmax(torch.squeeze(y_pred), dim=0)\n",
    "    sample=torch.multinomial(probs, 1)\n",
    "    moliere+=itos[sample.item()]\n",
    "print(moliere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado **no es perfecto**, pero se reconocen algunas palabras y una estructura de frases similar al archivo *\"moliere.txt\"*. ¡No está mal para una RNN de **una sola capa**!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo mejorar los resultados?** Algunas ideas:\n",
    "- Aumentar el **número de capas** o el **tamaño de la capa oculta**.\n",
    "- Usar *embeddings* en lugar de *one-hot encoding*.\n",
    "- Probar variantes de RNN como [LSTM](https://arxiv.org/pdf/1308.0850) o [GRU](https://arxiv.org/abs/1409.1259).\n",
    "- ~~Usar una arquitectura *transformer*~~ *(¡spoiler!)*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitaciones de las RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque las RNN fueron **centrales en NLP y *deep learning***, tienen limitaciones que las hacen poco prácticas para modelos grandes:\n",
    "\n",
    "- **Contexto teóricamente infinito**, pero su estructura secuencial **dificulta propagar información en secuencias largas**.\n",
    "- **Problema del *vanishing gradient***: los gradientes se desvanecen en secuencias largas.\n",
    "- **Dificultad para paralelizar**: los GPU están optimizados para cálculos paralelos, pero las RNN son **inherentemente secuenciales** (entrenamiento más lento).\n",
    "- **Estructura fija**: no siempre captura relaciones complejas entre datos.\n",
    "\n",
    "Desde la llegada de los [*transformers*](https://arxiv.org/pdf/1706.03762), el uso de RNN ha disminuido significativamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
