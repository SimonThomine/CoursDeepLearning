{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Diffusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cours, nous allons implémenter pas à pas un modèle de diffusion sur le dataset MNIST.   \n",
    "Le cours est grandement inspiré du [github minDiffusion](https://github.com/cloneofsimo/minDiffusion/tree/master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aquilae/anaconda3/envs/dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset : 60000\n",
      "Taille d'une image : (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([T.ToTensor(), T.Normalize((0.5,), (1.0))])\n",
    "\n",
    "dataset = MNIST(\"./../data\",train=True,download=True,transform=transform)\n",
    "print('Taille du dataset :', len(dataset))\n",
    "print('Taille d\\'une image :', dataset[0][0].numpy().shape)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un modèle de diffusion, il faut générer du bruit pour chaque étape de diffusion. Pour cela, on va créer nos plages de valeurs de bruit comprises entre $\\beta_1$ et $\\beta_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpm_schedules(beta1: float, beta2: float, T: int):\n",
    "\n",
    "  # On vérifie que beta1 et beta2 sont bien dans l'intervalle (0, 1) et que beta1 < beta2\n",
    "  assert beta1 < beta2 < 1.0, \"beta1 et beta2 doivent être dans l'intervalle (0, 1)\"\n",
    "\n",
    "  # On crée un vecteur de taille T+1 allant de beta1 à beta2 qui échantillonne linéairement l'intervalle [beta1, beta2]\n",
    "  beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
    "  \n",
    "  # On calcule toutes les valeurs qui seront nécessaires pour les calculs de l'optimisation\n",
    "  sqrt_beta_t = torch.sqrt(beta_t)\n",
    "  alpha_t = 1 - beta_t\n",
    "  log_alpha_t = torch.log(alpha_t)\n",
    "  alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
    "\n",
    "  sqrtab = torch.sqrt(alphabar_t)\n",
    "  oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
    "\n",
    "  sqrtmab = torch.sqrt(1 - alphabar_t)\n",
    "  mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
    "\n",
    "  return {\n",
    "    \"alpha_t\": alpha_t,  # \\alpha_t\n",
    "    \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
    "    \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
    "    \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
    "    \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
    "    \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
    "    \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant créer notre modèle ! En général, on prend une architecture U-Net mais en pratique, on peut prendre un peu n'importe quoi. Pour plus de simplicité, on va prendre un modèle convolutif tout bête. Aussi, normalement le modèle prend l'étape $t$ en entrée mais dans notre modèle simplifié, nous n'allons pas le faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(in_channels, out_channels,kernel_size=7, stride=1, padding=3):\n",
    "  return nn.Sequential(\n",
    "    nn.Conv2d(in_channels, out_channels, kernel_size,stride, padding),\n",
    "    nn.BatchNorm2d(out_channels),\n",
    "    nn.LeakyReLU())\n",
    "\n",
    "class model(nn.Module):\n",
    "\n",
    "  def __init__(self, channels: int) -> None:\n",
    "    super(model, self).__init__()\n",
    "    # Très petit modèle\n",
    "    self.conv = nn.Sequential(  \n",
    "      conv_bn_relu(channels, 64),\n",
    "      conv_bn_relu(64, 128),\n",
    "      conv_bn_relu(128, 256),\n",
    "      conv_bn_relu(256, 512),\n",
    "      conv_bn_relu(512, 256),\n",
    "      conv_bn_relu(256, 128),\n",
    "      conv_bn_relu(128, 64),\n",
    "      nn.Conv2d(64, channels, 3, padding=1),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que l'on a notre modèle pour passer d'une étape à une autre, construisons le modèle global : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self,model: nn.Module,betas: Tuple[float, float],n_T: int,criterion: nn.Module = nn.MSELoss()) -> None:\n",
    "        super(DDPM, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "        # Permet de stocker les ddpm schedules dans le modèle pour accéder aux valeurs plus facilement\n",
    "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
    "            self.register_buffer(k, v)\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.criterion = criterion\n",
    "\n",
    "    # Etape d'entrainement\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Makes forward diffusion x_t, and tries to guess epsilon value from x_t using eps_model.\n",
    "        This implements Algorithm 1 in the paper.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Génère un entier aléatoire entre 1 et n_T pour choisir un t aléatoire\n",
    "        _ts = torch.randint(1, self.n_T, (x.shape[0],)).to(x.device) \n",
    "        # Génère un bruit aléatoire de la même taille que x\n",
    "        eps = torch.randn_like(x)  # eps ~ N(0, 1)\n",
    "\n",
    "            # On applique le bruit gaussien à x pour obtenir x_t\n",
    "        x_t = (self.sqrtab[_ts, None, None, None] * x+ self.sqrtmab[_ts, None, None, None] * eps)  \n",
    "        # On va essayer de prédire le bruit epsilon à partir de x_t\n",
    "        pred_eps = self.model(x_t)\n",
    "        return self.criterion(eps, pred_eps)\n",
    "\n",
    "    # Génération d'un échantillon\n",
    "    def sample(self, n_sample: int, size, device) -> torch.Tensor:\n",
    "        \n",
    "        # On génère un échantillon aléatoire de taille n_sample à partir d'une distribution normale centrée réduite\n",
    "        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1)\n",
    "\n",
    "        # On va appliquer le processus de diffusion inverse pour générer un échantillon (ça prend du temps \n",
    "        # car on doit appliquer le processus de diffusion à chaque étape)\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
    "            eps = self.model(x_i)\n",
    "            x_i = (self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])+ self.sqrt_beta_t[i] * z)\n",
    "\n",
    "        return x_i\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ddpm = DDPM(model=model(channels=1), betas=(1e-4, 0.02), n_T=1000)\n",
    "ddpm.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà, notre implémentation simple est terminée ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons maintenant à l'entrainement du modèle. On va diminuer grandement la taille du dataset (seulement 1000 éléments) mais l'entraînement sera quand même très long. Je ne vous conseille pas d'essayer sauf si vous avez un très bon GPU à disposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=100\n",
    "n_T=1000\n",
    "optimizer = torch.optim.Adam(ddpm.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation=[]\n",
    "for i in range(0,epoch+1):\n",
    "  ddpm.train()\n",
    "  loss_ema = None\n",
    "  for x, _ in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    loss = ddpm(x)\n",
    "    loss.backward()\n",
    "    if loss_ema is None:\n",
    "      loss_ema = loss.item()\n",
    "    else:\n",
    "      loss_ema = 0.9 * loss_ema + 0.1 * loss.item()\n",
    "    optimizer.step()\n",
    "  print(f\"epoch {i}, loss: {loss_ema:.4f}\")\n",
    "  if i % 10 == 0:\n",
    "    ddpm.eval()\n",
    "    with torch.no_grad():\n",
    "      print('ici')\n",
    "      xh = ddpm.sample(4, (1, 28, 28), device)\n",
    "      grid = make_grid(xh, nrow=4)\n",
    "      generation.append(grid)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grid in generation:\n",
    "  grid_image = grid.permute(1, 2, 0).cpu().numpy()\n",
    "  # Afficher l'image\n",
    "  plt.imshow(grid_image)\n",
    "  plt.axis('off')  # Pour masquer les axes\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
