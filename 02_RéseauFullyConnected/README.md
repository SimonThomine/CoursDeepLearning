# üß† R√©seau Fully Connected üß† 
Ce cours introduit le fonctionnement d'un r√©seau de neurones avec d'abord un exemple d'un r√©seau cod√© avec [micrograd](https://github.com/karpathy/micrograd/tree/master) pour permettre d'explorer cette library pour bien comprendre le fonctionnement. Une [version fran√ßaise MicrogradFR](../MicrogradFR/README.md) est disponible dans ce repository.   
Ensuite, pour introduire la library pytorch, le m√™me exemple est reconstruit mais en utilisant pytorch au lieu de micrograd.  
Le dernier notebook de cette partie introduit des techniques avanc√©es d'entra√Ænement de r√©seau de neurones qu'il est utile de conna√Ætre pour am√©liorer les performances de nos r√©seaux. 

## Notebook 1Ô∏è‚É£ : [Mon premier r√©seau](01_MonPremierR√©seau.ipynb)
Ce notebook propose une premi√®re implementation d'un r√©seau de neurones avec la library micrograd. Un dataset al√©atoire est cr√©e et on utilise la descente du gradient stochastique pour entra√Æner le mod√®le.

## Notebook 2Ô∏è‚É£ : [Pytorch introduction](02_PytorchIntroduction.ipynb)
Ce notebook r√©sout exactement le m√™me probl√®me que le notebook pr√©c√©dent mais en utilisant la library pytorch. La library pytorch est l'une des library les plus utilis√©es en Deep Learning et il est important de savoir s'en servir.

## Notebook 3Ô∏è‚É£ : [Techniques avanc√©es](03_TechniquesAvanc√©es.ipynb)
Ce notebook s'attaque au probl√®me plus complexe de classification de chiffres sur la dataset MNIST. Des techniques de r√©gularisation ainsi que la BatchNorm sont √©galement introduites.