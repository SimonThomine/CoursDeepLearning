{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones récurrents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cours, nous allons introduire les réseaux de neurones récurrents (RNN) dans le cadre de la prédiction du prochain caractère. Pour ce faire, nous allons nous baser sur l'architecture décrite dans le papier [Recurrent neural network based language model](https://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf) qui présente une version basique de RNN pour la prédiction du prochain caractère.  \n",
    "\n",
    "La motivation derrière l'utilisation d'un RNN pour cette tâche permet de ne pas avoir à spécifier une taille de contexte pour l'entraînement du modèle contrairement aux deux modèles basées sur des réseaux fully connected que nous avons vu dans les notebooks précédents. \n",
    "\n",
    "Les RNN ont pour motivation de garder une information de contexte peu importe la longueur de la séquence. C'est une idée très sensé sur le papier mais il y a de grosses limitations pour l'optimisation.  \n",
    "\n",
    "<img src=\"images/rnn.png\" alt=\"rnn\" width=\"250\"/>    \n",
    "\n",
    "Figure extraite de l'article original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctionnement de l'architecture RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'architecture de réseau de neurones récurrents se base sur une approche séquentiel. Les caractères vont être passé un par un dans le modèle et la valeur du caractère suivant dépend du \"state\" gardé en mémoire et de l'élément actuel. Le \"state\" contient les informations de contexte de tous les caractères précédents.  \n",
    "\n",
    "Posons le problème mathématiquement : \n",
    "Un RNN est constitué de 3 éléments : l'input $x$, le state (hidden layer) $s$ et l'output $y$. On introduit également le temps $t$ qui rajoute la composante temporelle pour le traitement séquentiel.   \n",
    "$x$ au temps $t$ est alors défini comme :    \n",
    "$x(t)=w(t) + s(t-1)$ où $w()$ est l'opération de one_hot encoding  \n",
    "Et ensuite, on estime $s(t)$ et $y(t)$ :    \n",
    "$s(t)=sigmoid(x(t))$   \n",
    "$y(t)=softmax(s(t))$    \n",
    "\n",
    "On peut constater que ce modèle n'a en fait qu'un seul paramètre à ajuster : la dimension de la couche cachée $s$. \n",
    "\n",
    "Pour l'initialisation $s(0)$ peut être configuré comme un vecteur de petite valeurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser un RNN pour générer des prénoms n'est pas très intéressant car la taille de contexte est limitée car les prénoms ne sont jamais très longs. Pour ce type de tâches, il est intéressant d'utiliser un dataset avec un contexte conséquent.   \n",
    "Pour cela, nous utilons un fichier texte moliere.txt qui regroupe l'intégralité des dialogues des pièces de Molière.   \n",
    "Ce dataset a été crée à partir des oeuvres complètes de Molière disponibles sur le site [Gutenberg.org](Gutenberg.org). J'ai nettoyé un peu les données pour ne garder que les dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de caractères dans le dataset :  1687290\n"
     ]
    }
   ],
   "source": [
    "with open('moliere.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(\"Nombre de caractères dans le dataset : \", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est un gros dataset, pour avoir un temps de traitement raisonnables, prenons uniquement une partie de ce dataset, par exemple les 100 000 premiers caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de caractères dans le dataset :  100000\n"
     ]
    }
   ],
   "source": [
    "text=text[:100000]\n",
    "print(\"Nombre de caractères dans le dataset : \", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons les 250 premiers caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALÈRE.\n",
      "\n",
      "Eh bien, Sabine, quel conseil me donnes-tu?\n",
      "\n",
      "SABINE.\n",
      "\n",
      "Vraiment, il y a bien des nouvelles. Mon oncle veut résolûment que ma\n",
      "cousine épouse Villebrequin, et les affaires sont tellement avancées,\n",
      "que je crois qu'ils eussent été mariés dès aujo\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons le nombre de caractères différents : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !'(),-.:;?ABCDEFGHIJLMNOPQRSTUVYabcdefghijlmnopqrstuvxyz«»ÇÈÉÊàâæçèéêîïôùû\n",
      "Nombre de caractères différents :  76\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(\"Nombre de caractères différents : \", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un mapping de caractère à entiers et inversement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encore : prend un string et output une liste d'entiers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decode: prend une liste d'entiers et output un string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodons notre dataset en convertissant les string en int puis en le transformant en tenseur pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32, 12, 22, 61, 28, 16,  8,  0,  0, 16, 41,  1, 35, 42, 38, 46,  6,  1,\n",
      "        29, 34, 35, 42, 46, 38,  6,  1, 49, 53, 38, 44,  1, 36, 47, 46, 51, 38,\n",
      "        42, 44,  1, 45, 38,  1, 37, 47, 46, 46, 38, 51,  7, 52, 53, 11,  0,  0,\n",
      "        29, 12, 13, 20, 24, 16,  8,  0,  0, 32, 50, 34, 42, 45, 38, 46, 52,  6,\n",
      "         1, 42, 44,  1, 56,  1, 34,  1, 35, 42, 38, 46,  1, 37, 38, 51,  1, 46,\n",
      "        47, 53, 54, 38, 44, 44, 38, 51,  8,  1, 23, 47, 46,  1, 47, 46, 36, 44,\n",
      "        38,  1, 54, 38, 53, 52,  1, 50, 69, 51, 47, 44, 75, 45, 38, 46, 52,  1,\n",
      "        49, 53, 38,  1, 45, 34,  0, 36, 47, 53, 51, 42, 46, 38,  1, 69, 48, 47,\n",
      "        53, 51, 38,  1, 32, 42, 44, 44, 38, 35, 50, 38, 49, 53, 42, 46,  6,  1,\n",
      "        38, 52,  1, 44, 38, 51,  1, 34, 39, 39, 34, 42, 50, 38, 51,  1, 51, 47,\n",
      "        46, 52,  1, 52, 38, 44, 44, 38, 45, 38, 46, 52,  1, 34, 54, 34, 46, 36,\n",
      "        69, 38, 51,  6,  0, 49, 53, 38,  1, 43, 38,  1, 36, 50, 47, 42, 51,  1,\n",
      "        49, 53,  3, 42, 44, 51,  1, 38, 53, 51, 51, 38, 46, 52,  1, 69, 52, 69,\n",
      "         1, 45, 34, 50, 42, 69, 51,  1, 37, 68, 51,  1, 34, 53, 43, 47])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:250]) # Les 250 premiers caractères encodé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare training et validation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # 90% pour le train et 10% pour la validation\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Chaque itération de l'entraînement correspondra à un passage dans l'intégralité du dataset de manière séquentielle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est maintenant temps de créer notre modèle !  \n",
    "\n",
    "Dans le papier, il est indiqué que l'entrée du modèle (le caractère) est encodé en one hot et qu'il est ensuite sommé avec le state à $t-1$. On va donc avoir besoin de deux couches fully connected, la première pour transformer l'entrée $x(t)$ en  state au temps t$s(t)$ et la seconde pour transformer $s(t)$ en $y(t)$, notre prédiction. \n",
    "\n",
    "<img src=\"images/rnn_math.png\" alt=\"rnn_math\" width=\"250\"/>    \n",
    "\n",
    "Equation extraite de l'article original. $f$ est la fonction sigmoid et $g$ la softmax.\n",
    "\n",
    "**Note** : L'[article](https://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf) est très accessible et concis, je vous invite à le lire. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn(nn.Module): \n",
    "  def __init__(self,hidden_dim,vocab_size) -> None:\n",
    "    super(rnn, self).__init__()\n",
    "    self.hidden_to_hidden=nn.Linear(hidden_dim+vocab_size, hidden_dim)\n",
    "    self.hidden_to_output=nn.Linear(hidden_dim, vocab_size)\n",
    "    self.vocab_size=vocab_size\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.sigmoid=nn.Sigmoid() \n",
    "    \n",
    "  # Le réseau prend en entrée le caractère actuel et le state précédent\n",
    "  def forward(self, x,state):\n",
    "    # On one-hot encode le caractère\n",
    "    x = torch.nn.functional.one_hot(x, self.vocab_size).float()\n",
    "    if state is None:\n",
    "      # Si on a pas de state (début de la séquence), on initialise le state avec des petites valeurs aléatoires\n",
    "      state = torch.randn(self.hidden_dim) * 0.1\n",
    "    x = torch.cat((x, state), dim=-1)  # Concaténation de x et du state\n",
    "    state = self.sigmoid(self.hidden_to_hidden(x)) # Calcul du nouveau state\n",
    "    output = self.hidden_to_output(state) # Calcul de l'output\n",
    "    # On renvoie l'output et le state pour le prochain pas de temps\n",
    "    return output, state.detach() # detach() pour éviter de propager le gradient dans le state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons nos paramètres d'entraînement : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aquilae/anaconda3/envs/dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr=0.1\n",
    "hidden_dim=128\n",
    "model=rnn(hidden_dim,vocab_size)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est temps d'entraîner le modèle !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Loss: 2.42064296\n",
      "Epoch: 1 \t Loss: 2.02932206\n",
      "Epoch: 2 \t Loss: 1.91027851\n",
      "Epoch: 3 \t Loss: 1.84189548\n",
      "Epoch: 4 \t Loss: 1.79332830\n",
      "Epoch: 5 \t Loss: 1.75458955\n",
      "Epoch: 6 \t Loss: 1.72111627\n",
      "Epoch: 7 \t Loss: 1.69267295\n",
      "Epoch: 8 \t Loss: 1.66852771\n",
      "Epoch: 9 \t Loss: 1.64716606\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    state=None\n",
    "    running_loss = 0\n",
    "    n=0\n",
    "    for i in range(len(train_data)-1):\n",
    "        x = train_data[i]\n",
    "        y = train_data[i+1]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred,state = model.forward(x,state)\n",
    "        loss = criterion(y_pred, y)\n",
    "        running_loss += loss.item()\n",
    "        n+=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: {0} \\t Loss: {1:.8f}\".format(epoch, running_loss/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le modèle est entraîné, on va pouvoir générer du Molière !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "LÉLIE.\n",
      "\n",
      "Vous dout asspagé bodrt, ouis horrite.\n",
      "\n",
      "LÉLIE.\n",
      "\n",
      "Oui mageît;\n",
      "Cons tourre un vous sous l'avousont avic'obal nant fivectie,\n",
      "Mans cet avois le soup jommoye,\n",
      "D'achiviller cet il vivons ce vire.\n",
      "\n",
      "MASCARILLE.\n",
      "\n",
      "Adieur tagours.\n",
      "\n",
      "LÉLIE.\n",
      "\n",
      "Le forle;\n",
      "A \n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "moliere='.'\n",
    "sequence_length=250\n",
    "state=None\n",
    "for i in range(sequence_length):\n",
    "    x = torch.tensor(encode(moliere[-1]), dtype=torch.long).squeeze()\n",
    "    y_pred,state = model.forward(x,state)\n",
    "    probs=F.softmax(torch.squeeze(y_pred), dim=0)\n",
    "    sample=torch.multinomial(probs, 1)\n",
    "    #print(sample)\n",
    "    moliere+=itos[sample.item()]\n",
    "print(moliere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce n'est pas très convaincant ... Mais on reconnaît quand même quelques mots et un agencement des phrases similaire au fichier \"moliere.txt\". Ce n'est finalement pas si mal pour un réseau récurrent d'une seule couche. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment améliorer nos résultats ?** : Pour améliorer les résultats, il y a plusieurs options possibles :\n",
    "- On peut augmenter le nombre de couche récurrente ou augmenter la dimension de la couche cachée.\n",
    "- On peut utiliser un embedding plutôt qu'un one hot encoding\n",
    "- On peut utiliser d'autres variantes de RNN comme [LSTM](https://arxiv.org/pdf/1308.0850) ou [GRU](https://arxiv.org/abs/1409.1259)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
