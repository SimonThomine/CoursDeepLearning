{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation d'un GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est temps de passer à l'implémentation d'un GAN. Pour cela, nous allons nous baser sur le papier [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434) pour générer des images de chiffres similaires à ceux du dataset MNIST. Dans un premier temps, nous allons implémenter le GAN de base puis nous le modifierons pour en faire un *conditional* GAN.\n",
    "\n",
    "<img src=\"images/dcgan.png\" alt=\"dcgan\" width=\"800\"/>\n",
    "\n",
    "Architecture du generateur de DCGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par charger notre dataset MNIST :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du dataset d'entrainement :  60000\n",
      "taille d'une image :  (1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32,32)),\n",
    "])\n",
    "train_data = datasets.MNIST(root='./../data', train=True, transform=transform, download=True)\n",
    "test_data = datasets.MNIST(root='./../data', train=False, transform=transform, download=True)\n",
    "\n",
    "print(\"taille du dataset d'entrainement : \",len(train_data))\n",
    "print(\"taille d'une image : \",train_data[0][0].numpy().shape) \n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisons quelques images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "  plt.subplot(1, 5, i+1)\n",
    "  plt.imshow(train_data[i][0].squeeze(), cmap='gray')\n",
    "  plt.axis('off')\n",
    "  plt.title(train_data[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de notre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant implémenter nos deux modèles. Commençons par regarder les spécificités d'architecture décrites dans la papier. \n",
    "\n",
    "<img src=\"images/dcgan_arch.png\" alt=\"dcgan_arch\" width=\"800\"/>\n",
    "\n",
    "A partir de ces informations et de la figure du papier (voir plus haut dans le notebook), on peut construire notre modèle générateur. Comme on travaille sur des images de taille $28 \\times 28$ au lieu de $64 \\times 64$ dans le papier, on va faire une architecture plus réduite.\n",
    "\n",
    "**Note** : Dans le papier, les auteurs disent utiliser des *fractional-strided convolutions*. Il s'agit en fait de convolutions transposées et le terme *fractional-strided convolutions* n'est plus vraiment utilisé de nos jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "def convT_bn_relu(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding,bias=False),\n",
    "    nn.BatchNorm2d(out_channels),\n",
    "    nn.ReLU()\n",
    "  )\n",
    "\n",
    "class generator(nn.Module):\n",
    "  def __init__(self, z_dim=100,features_g=64):\n",
    "    super(generator, self).__init__()\n",
    "    self.gen = nn.Sequential(\n",
    "      convT_bn_relu(z_dim, features_g*8, kernel_size=4, stride=1, padding=0),\n",
    "      convT_bn_relu(features_g*8, features_g*4, kernel_size=4, stride=2, padding=1),\n",
    "      convT_bn_relu(features_g*4, features_g*2, kernel_size=4, stride=2, padding=1),\n",
    "      nn.ConvTranspose2d(features_g*2, 1, kernel_size=4, stride=2, padding=1),\n",
    "      nn.Tanh()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.gen(x)\n",
    "  \n",
    "z= torch.randn(64,100,1,1)\n",
    "gen = generator()\n",
    "img = gen(z)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le papier ne décrit pas directement l'architecture du discriminateur. Nous allons globalement reprendre l'architecture du générateur mais dans l'autre sens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "def conv_bn_lrelu(in_channels, out_channels, kernel_size, stride, padding):\n",
    "  return nn.Sequential(\n",
    "    nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,bias=False),\n",
    "    nn.BatchNorm2d(out_channels),\n",
    "    nn.LeakyReLU()\n",
    "  )\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "  def __init__(self, features_d=64) -> None:\n",
    "    super().__init__()\n",
    "    self.discr = nn.Sequential(\n",
    "      conv_bn_lrelu(1, features_d, kernel_size=3, stride=2, padding=1),\n",
    "      conv_bn_lrelu(features_d, features_d*2, kernel_size=3, stride=2, padding=1),\n",
    "      conv_bn_lrelu(features_d*2, features_d*4, kernel_size=3, stride=2, padding=1),\n",
    "      nn.Conv2d(256, 1, kernel_size=3, stride=2, padding=0),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.discr(x)\n",
    "dummy = torch.randn(64,1,32,32)\n",
    "disc = discriminator()\n",
    "out = disc(dummy)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est temps de passer aux choses sérieuses. La boucle d'entraînement d'un GAN est bien plus complexe que les boucles d'entraînements des modèles que nous avons vu jusqu'à présent.   \n",
    "Commençons par définir nos hyperparamètres d'entraînement et par initialiser nos modèles :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr=0.001\n",
    "z_dim = 100\n",
    "features_d = 64\n",
    "features_g = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gen = generator(z_dim, features_g).to(device)\n",
    "disc = discriminator(features_d).to(device)\n",
    "\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons également créer un bruit *fixed_noise* pour évaluer visuellement notre modèle à chaque étape d'entraînement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, z_dim, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de consttuire notre boucle d'entraînement, récapitulons les étapes que nous devons faire : \n",
    "- On commence par récuperer *batch_size* éléments du dataset d'entraînement et on prédit les labels avec notre discriminateur\n",
    "- Ensuite, on génére *batch_size* éléments avec notre générateur et on prédit les labels\n",
    "- On va ensuite mettre à jour les poids du modèle discriminateur à partir des deux *loss*\n",
    "- On va ensuite à nouveau prédire les labels des données générées (car on a mis à jour le discriminateur entre temps)\n",
    "- A partir de ces valeurs, on calcule le *loss* et on met à jour notre générateur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
